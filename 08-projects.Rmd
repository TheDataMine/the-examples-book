# Projects {#projects}

## Templates

Our course project template can be found [here](https://raw.githubusercontent.com/TheDataMine/the-examples-book/master/files/project_template.Rmd), or on Scholar: 

`/class/datamine/apps/templates/project_template.Rmd`

Students in STAT 19000, 29000, and 39000 are to use this as a template for all project submissions. The template includes a code chunk that "activates" our Python environment, and adjusts some default settings. In addition, it provides examples on how to include solutions for Python, R, Bash, and SQL. Every question should be clearly marked with a third-level header (using 3 `#`s) followed by `Question X` where `X` is the question number. Sections for question solutions should be added or removed based on the number of questions in the given project. All code chunks are to be run and solutions displayed for the compiled PDF submission.

Any format or template related questions should be asked in Piazza.

## STAT 19000

## STAT 29000

### Project 2

---

**Motivation:** The ability to quickly reproduce an analysis is important. It is often necessary that other individuals will need to be able to understand and reproduce an analysis. This concept is so important there are classes solely on reproducible research! In fact, there are papers that investigate and highlight the lack of reproducibility in various fields. If you are interested in reading about this topic, a good place to start is the paper titled ["Why Most Published Research Findings Are False"](https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124), by John Ioannidis (2005). 

**Context:** Making your work reproducible is extremely important. We will focus on the computational part of reproducibility. We will learn RMarkdown to document your analyses so others can easily understand and reproduce the computations that led to your conclusions. Pay close attention as future project templates will be RMarkdown templates.

**Scope:** Understand Markdown, RMarkdown, and how to use it to make your data analysis reproducible.

**Learning objectives:**

```{block, type="bbox"}
- Use Markdown syntax within an Rmarkdown document to achieve various text transformations.
- Use RMarkdown code chunks to display and/or run snippets of code.
```

You can find useful examples that walk you through relevant material in The Examples Book:

https://thedatamine.github.io/the-examples-book

It is highly recommended to read through, search, and explore these examples to help solve problems in this project.

**Important note:** It is highly recommended that you use https://rstudio.scholar.rcac.purdue.edu/. Simply click on the link and login using your Purdue account credentials. Use another system at your own risk. The version of RStudio on https://desktop.scholar.rcac.purdue.edu/ (which uses ThinLinc), is 99.9.9, and is known to have some strange issues when running code chunks.

Don't forget the very useful documentation shortcut `?`. To use, simply type `?` in the console, followed by the name of the function you are interested in. 

You can also look for package documentation by using `help(package=PACKAGENAME)`, so for example, to see the documentation for the package `ggplot2`, we could run:

```{r, eval=F}
help(package=ggplot2)
```

Sometimes it can be helpful to see the source code of a defined function. A [function](https://www.tutorialspoint.com/r/r_functions.htm) is any chunk of organized code that is used to perform an operation. Source code is the underlying `R` or `c` or `c++` code that is used to create the function. To see the source code of a defined function, type the function's name without the `()`. For example, if we were curious about what the function `Reduce` does, we could run:

```{r, eval=F}
Reduce
```

Occasionally this will be less useful as the resulting code will be code that calls `c` code we can't see. Other times it will allow you to understand the function better.

##### 1. Make the following text (including the asterisks) bold: `This needs to be **very** bold`. Make the following text (including the underscores) italicized: `This needs to be _very_ italicized.`

**Hint:** *Try mixing and matching ways to embolden or italicize text. Alternatively, look up "escaping characters in markdown", or see [here](https://thedatamine.github.io/the-examples-book/faqs.html#escape-characters).*

**Hint:** *Be sure to check out the [Rmarkdown Cheatsheet](https://rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf) and our section on [Rmarkdown in the book](https://thedatamine.github.io/the-examples-book/r.html#r-rmarkdown).*

**Note:** *Rmarkdown is essentially Markdown + the ability to run and display code chunks. In this question, we are actually using Markdown within Rmarkdown!*

**Relevant topics:** *[rmarkdown](https://thedatamine.github.io/the-examples-book/r.html#r-rmarkdown), [escaping characters](https://thedatamine.github.io/the-examples-book/faqs.html#escape-characters)*

```{block, type="bbox"}
**Item(s) to submit:**

- Fill in the chunk under (1) in the `stat29000project02template.Rmd` file with 2 lines of markdown text. Note that when compiled, this text will be unmodified, regular text.
```

##### 2. Create an unordered list of your top 3 favorite academic interests (some examples could include: machine learning, operating systems, forensic accounting, etc.). Create another *ordered* list that ranks your academic interests in order of most interested to least interested.

**Hint:** *You can learn what ordered and unordered lists are [here]( https://rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf).*

**Note:** *Similar to (1a), in this question we are dealing with Markdown. If we were to copy and paste the solution to this problem in a Markdown editor, it would be the same result as when we Knit it here.*

**Relevant topics:** *[rmarkdown](https://thedatamine.github.io/the-examples-book/r.html#r-rmarkdown)*

```{block, type="bbox"}
**Item(s) to submit:**

- Create the lists under (2) in the `stat29000project02template.Rmd` file. Note that when compiled, this text will appear as nice, formatted lists.
```

##### 3. Browse https://www.linkedin.com/ and read some profiles. Pay special attention to accounts with an "About" section. Write your own personal "About" section using Markdown. Include the following:

- A header (your choice of size) that says "About".
- A horizontal rule directly underlining the header.
- The text of your personal "About" section that you would feel comfortable uploading to linkedin, including at least 1 link.

**Relevant topics:** *[rmarkdown](https://thedatamine.github.io/the-examples-book/r.html#r-rmarkdown)*

```{block, type="bbox"}
**Item(s) to submit:**

- Create the described profile under (3) in the `stat29000project02template.Rmd` file.
```

##### 4. Your co-worker wrote a report, and has asked you to beautify it. Knowing Rmarkdown, you agreed. Spruce up the report found under (4) in `stat29000project02template.Rmd`. At a minimum:

- Make the title pronounced.
- Make all links appear as a word or words, rather than the long-form URL.
- Organize all code into code chunks where code and output are displayed. If the output is really long, just display the code.
- Make the calls to the `library` function and the `install.packages` function be evaluated but not displayed. Make sure all warnings and errors that may eventually occur, do not appear in the final document.

Feel free to make any other changes that make the report more visually pleasing.

**Relevant topics:** *[rmarkdown](https://thedatamine.github.io/the-examples-book/r.html#r-rmarkdown)*

```{block, type="bbox"}
**Item(s) to submit:**

- Spruce up the "document" under (4) in the `stat29000project02template.Rmd` file.
```

##### 5. Create a plot using a built-in dataset like `iris`, `mtcars`, or `Titanic`, and display the plot using a code chunk. Make sure the code used to generate the plot is hidden. Include a descriptive caption for the image.

**Relevant topics:** *[rmarkdown](https://thedatamine.github.io/the-examples-book/r.html#r-rmarkdown), [plotting in r](https://thedatamine.github.io/the-examples-book/r.html#r-plotting)*

```{block, type="bbox"}
**Item(s) to submit:**

- Code chunk under (5) that creates and displays a plot using a built-in dataset like `iris`, `mtcars`, or `Titanic`.
```

##### 6. Insert the following code chunk under (5) in `stat29000project02template.Rmd`. Try knitting the document. Something should go wrong. Fix the problem and knit again. If another problem appears, fix it. What was the first problem? What was the second problem?
       
````markdown
`r ''````{r install-packages}
plot(my_variable)
```
````

**Hint:** *Take a close look at the name we give our code chunk.*

**Hint:** *Take a look at the code chunk where `my_variable` is declared.*

**Relevant topics:** *[rmarkdown](https://thedatamine.github.io/the-examples-book/r.html#r-rmarkdown)*

```{block, type="bbox"}
**Item(s) to submit:**

- The modified version of the inserted code that fixes both problems.
- A sentence explaining what the first problem was.
- A sentence explaining what the second problem was.
```

---

### Project 3

---

**Motivation:** The ability to navigate a shell, like `bash`, and use some of its powerful tools, is very useful. The number of disciplines utilizing data in new ways is ever-growing, and as such, it is very likely that many of you will eventually encounter a scenario where knowing your way around a terminal will be useful. We want to expose you to some of the most useful `bash` tools, help you navigate a filesystem, and even run `bash` tools from within an RMarkdown file in RStudio.

**Context:** At this point in time, you will each have varying levels of familiarity with Scholar. In this project we will learn how to use the terminal to navigate a UNIX-like system, experiment with various useful commands, and learn how to execute bash commands from within RStudio in an RMarkdown file.

**Scope:** bash, RStudio

**Learning objectives:**

```{block, type="bbox"}
- Distinguish differences in /home, /scratch, and /class.
- Navigating UNIX via a terminal: ls, pwd, cd, ., .., ~, etc.
- Analyzing file in a UNIX filesystem: wc, du, cat, head, tail, etc.
- Creating and destroying files and folder in UNIX: scp, rm, touch, cp, mv, mkdir, rmdir, etc.
- Utilize other Scholar resources: rstudio.scholar.rcac.purdue.edu, notebook.scholar.rcac.purdue.edu, desktop.scholar.rcac.purdue.edu, etc.
- Use `man` to read and learn about UNIX utilities.
- Run `bash` commands from within and RMarkdown file in RStudio.
```

#### Dataset: ??

#### Public: ??

There are a variety of ways to connect to Scholar. In this class, we will _primarily_ connect to RStudio Server by opening a browser and navigating to https://rstudio.scholar.rcac.purdue.edu/, entering credentials, and using the excellent RStudio interface. 

##### 1. Navigate to https://rstudio.scholar.rcac.purdue.edu/ and login. Take some time to click around and explore this tool. We will be writing and running Python, R, SQL, and `bash` all from within this interface. Navigate to `Tools > Global Options ...`. Explore this interface and make at least 2 modifications. List what you changed.

Here are some changes Kevin likes:

- Uncheck "Restore .Rdata into workspace at startup".
- Change tab width 4.
- Check "Soft-wrap R source files".
- Check "Highlight selected line".
- Check "Strip trailing horizontal whitespace when saving".
- Uncheck "Show margin".

```{block, type="bbox"}
**Item(s) to submit:**

- List of modifications you made to your Global Options.
```

##### 2. There are four primary panes, each with various tabs. In one of the panes there will be a tab labeled "Terminal". Click on that tab. This terminal by default will run a `bash` shell right within Scholar, the same as if you connected to Scholar using ThinLinc, and opened a terminal. Very convenient! What is the default directory of your bash shell? In our list of relevant topics, we've included links to a variety of UNIX commands that may help you solve this problem. Some of the tools are super simple to use, and some are a little bit more difficult. 

**Hint:** Start by reading the section on `man`. `man` stands for manual, and you can find the "official" documentation for the command by typing `man <command_of_interest>`. For example:

```{bash, eval=F}
# read the manual for the `man` command
# use "k" or the up arrow to scroll up, "j" or the down arrow to scroll down
man man 
```

**Relevant topics:** [man](#man), [cd](#cd), [pwd](#pwd), [ls](#ls), [~](#dots), [..](#dots), [.](#dots)

```{block, type="bbox"}
**Item(s) to submit:**

- The full filepath of default directory (home directory). Ex: Kevin's is: `/home/kamstut`
- The `bash` code used to show your home directory or current working directory when the `bash` shell is first launched.
```

##### 3. Learning to navigate away from our home directory to other folders, and back again, is vital. Perform the following actions, in order:

- Write a single command to navigate to the folder containing our full datasets: `/class/datamine/data`.
- Write a command to confirm you are in the correct folder. 
- Write a command to list the files and directories within the data directory. 
- What are the names of the files? Write another command to return back to your home directory. 
- Write a command to confirm you are in the correct folder.

Note: `/` is commonly referred to as the root directory in a linux/unix filesystem. Think of it as a folder that contains _every_ other folder in the computer. `/home` is a folder within the root directory. `/home/kamstut` is the full filepath of Kevin's home directory. There is a folder `home` inside the root directory. Inside `home` is another folder named `kamstut` which is Kevin's home directory. 

**Relevant topics:** [man](#man), [cd](#cd), [pwd](#pwd), [ls](#ls), [~](#dots), [..](#dots), [.](#dots)

```{block, type="bbox"}
**Item(s) to submit:**

- Command used to navigate to the data directory.
- Command used to confirm you are in the data directory.
- Command used to list files and folders.
- List of files and folders in the data directory.
- Command used to navigate back to the home directory.
- Commnad used to confirm you are in the home directory.
```

##### 4. Let's learn about two more important concepts. `.` refers to the current working directory, or the directory displayed when you run `pwd`. Unlike `pwd` you can use this when navigating the filesystem! So, for example, if you wanted to see the contents of a file called `my_file.txt` that lives in `/home/kamstut` (so, a full path of `/home/kamstut/my_file.txt`), and you are currently in `/home/kamstut`, you could run: `cat ./my_file.txt`. `..` represents the parent folder or the folder in which your current folder is contained. So let's say I was in `/home/kamstut/projects/` and I wanted to get the contents of the file `/home/kamstut/my_file.txt`. You could do: `cat ../my_file.txt`. When you navigate a directory tree using `.`,  `..`, and `~` you create paths that are called _relative_ paths because they are _relative_ to your current directory. Alternatively, a _full_ path or (_absolute_ path) is the path starting from the root directory. So `/home/kamstut/my_file.txt` is the _absolute_ path for `my_file.txt` and `../my_file.txt` is a _relative_ path. Perform the following actions, in order:

- Write a single command to navigate to the data directory.
- Write a single command to navigate back to your home directory using a _relative_ path. Do not use `~` or plain `cd`.

**Relevant topics:** [man](#man), [cd](#cd), [pwd](#pwd), [ls](#ls), [~](#dots), [..](#dots), [.](#dots)

```{block, type="bbox"}
**Item(s) to submit:**

- Command used to navigate to the data directory.
- Command used to navigate back to your home directory that uses a _relative_ path.
```

##### 5. In Scholar, when you want to deal with _really_ large amounts of data, you want to access scratch (you can read more [here](https://www.rcac.purdue.edu/policies/scholar/)). Your scratch directory on Scholar is located here: `/scratch/scholar/$USER`. `$USER` is an environment variable containing your username. Test it out: `echo /scratch/scholar/$USER`. Perform the following actions:

- Navigate to your scratch directory. 
- Confirm you are in the correct location.
- Execute `myquota`.
- Find the location of the `myquota` bash script.
- Output the first 5 and last 5 lines of the bash script. 
- Count the number of lines in the bash script.
- How many kilobytes is the script?

**Hint:** You could use each of the commands in the relevant topics once.

**Hint:** Commands often have _options_. _Options_ are features of the program that you can trigger specifically. You can see the _options_ of a command in the `DESCRIPTION` section of the `man` pages. For example: `man wc`. You can see `-m`, `-l`, and `-w` are all options for `wc`. To test this out:

```{bash, eval=F}
# using the default wc command. "/class/datamine/data/flights/1987.csv" is the first "argument" given to the command.
wc /class/datamine/data/flights/1987.csv
# to count the lines, use the -l option
wc -l /class/datamine/data/flights/1987.csv
# to count the words, use the -w option
wc -w /class/datamine/data/flights/1987.csv
# you can combine options as well
wc -w -l /class/datamine/data/flights/1987.csv
# some people like to use a single tack `-`
wc -wl /class/datamine/data/flights/1987.csv
# order doesn't matter
wc -lw /class/datamine/data/flights/1987.csv
```

**Hint:** The `-h` option for the `du` command is useful.

**Relevant topics:** [cd](#cd), [pwd](#pwd), [type](#type), [head](#head), [tail](#tail), [wc](#wc), [du](#du)

```{block, type="bbox"}
**Item(s) to submit:**

- Command used to navigate to your scratch directory.
- Command used to confirm your location.
- Output of `myquota`.
- Command used to find the location of the `myquota` script.
- Absolute path of the `myquota` script.
- Command used to output the first 5 lines of the `myquota` script.
- Command used to output the last 5 lines of the `myquota` script.
- Command used to find the number of lines in the `myquota` script.
- Number of lines in the script.
- Command used to find out how many kilobytes the script is.
- Number of kilobytes that the script takes up.
```

##### 6. Perform the following operations:

- Navigate to your scratch directory.
- Copy and paste the file: `/class/datamine/data/flights/1987.csv` to your current directory (scratch).
- Create a new directory called `my_test_dir` in your scratch folder.
- Move the file you copied to your scratch directory, into your new folder.
- Use `touch` to create an empty file named `im_empty.txt` in your scratch folder.
- Remove the directory `my_test_dir` _and_ the contents of the directory.
- Remove the `im_empty.txt` file.

**Hint:** `rmdir` may not be able to do what you think, instead, check out the options for `rm` using `man rm`.

**Relevant topics:** [cd](#cd), [cp](#cp), [mv](#mv), [mkdir](#mkdir), [touch](#touch), [rmdir](#rmdir), [rm](#rm)

```{block, type="bbox"}
**Item(s) to submit:**

- Command used to navigate to your scratch directory.
- Command used to copy the file, `/class/datamine/data/flights/1987.csv` to your current directory (scratch).
- Command used to create a new directory called `my_test_dir` in your scratch folder.
- Command used to move the file you copied earlier `1987.csv` into your new `my_test_dir` folder.
- Command used to create an empty file named `im_empty.txt` in your scratch folder.
- Command used to remove the directory _and_ the contents of the directory `my_test_dir`.
- Command used to remove the `im_empty.txt` file.
```

---

### Project 4

---

**Motivation:** The need to search files and datasets based on the text held within is common during various parts of the data wrangling process. `grep` is an extremely powerful UNIX tool that allows you to do so using regular expressions. Regular expressions are a structured method for searching for specified patterns. Regular expressions can be very complicated, [even professionals can make critical mistakes](https://blog.cloudflare.com/details-of-the-cloudflare-outage-on-july-2-2019/). With that being said, learning some of the basics is an incredible tool that will come in handy regardless of the language you are working in.

**Context:** We've just begun to learn the basics of navigating a file system in UNIX using various terminal commands. Now we will go into more depth with one of the most useful command line tools, `grep`, and experiment with regular expressions using `grep`, R, and later on, Python.

**Scope:** grep, regular expression basics, utilizing regular expression tools in R and Python

**Learning objectives:**

```{block, type="bbox"}
- Use `grep` to search for patterns within a dataset.
- Use `cut` to section off and slice up data from the command line.
- Use `wc` to count the number of lines of input.
```


You can find useful examples that walk you through relevant material in The Examples Book:

https://thedatamine.github.io/the-examples-book

It is highly recommended to read through, search, and explore these examples to help solve problems in this project.

**Important note:** It is highly recommended that you use https://rstudio.scholar.rcac.purdue.edu/. Simply click on the link and login using your Purdue account credentials. Use another system at your own risk. The version of RStudio on https://desktop.scholar.rcac.purdue.edu/ (which uses ThinLinc), is 99.9.9, and is known to have some strange issues when running code chunks.

Don't forget the very useful documentation shortcut `?`. To use, simply type `?` in the console, followed by the name of the function you are interested in. 

You can also look for package documentation by using `help(package=PACKAGENAME)`, so for example, to see the documentation for the package `ggplot2`, we could run:

```{r, eval=F}
help(package=ggplot2)
```

Sometimes it can be helpful to see the source code of a defined function. A [function](https://www.tutorialspoint.com/r/r_functions.htm) is any chunk of organized code that is used to perform an operation. Source code is the underlying `R` or `c` or `c++` code that is used to create the function. To see the source code of a defined function, type the function's name without the `()`. For example, if we were curious about what the function `Reduce` does, we could run:

```{r, eval=F}
Reduce
```

Occasionally this will be less useful as the resulting code will be code that calls `c` code we can't see. Other times it will allow you to understand the function better.

#### Dataset

The following questions will use the dataset found in Scholar:

`/class/datamine/data/movies_and_tv/the_office_dialogue.csv`

A public sample of the data can be found here: [the_office_dialogue.csv](https://www.datadepot.rcac.purdue.edu/datamine/movies-and-tv/the_office_dialogue.csv)

Answers to questions should all be answered using the full dataset located on Scholar. You may use the public samples of data to experiment with your solutions prior to running them using the full dataset.

`grep` stands for (g)lobally search for a (r)egular (e)xpression and (p)rint matching lines. As such, to best demonstrate `grep`, we will be using it with textual data. You can read about and see examples of `grep` [here](https://thedatamine.github.io/the-examples-book/unix.html#grep).

##### 1. Login to Scholar and use `grep` to find the dataset we will use this project. The dataset we will use is the only dataset to have the text "bears. beets. battlestar galactica.". What is the name of the dataset and where is it located?

**Relevant topics:** *[grep](https://thedatamine.github.io/the-examples-book/unix.html#grep)*

```{block, type="bbox"}
**Item(s) to submit:**

- The `grep` command used to find the dataset.
- The name and location in Scholar of the dataset.
- Use `grep` and `grepl` within R to solve a data-driven problem.
```

##### 2. `grep` prints the line that the text you are searching for appears in. In project 3 we learned a UNIX command to quickly print the first _n_ lines from a file. Use this command to get the headers for the dataset. As you can see, each line in the tv show is a row in the dataset. You can count to see which column the various bits of data live in.

Write a line of UNIX commands that searches for "bears. beets. battlestar galactica." and, rather than printing the entire line, prints only the character who speaks the line, as well as the line itself.

**Hint:** *The result if you were to search for "bears. beets. battlestar galactica." should be:*

```{txt}
"Jim","Fact. Bears eat beets. Bears. Beets. Battlestar Galactica."
```

**Hint:** *One method to solve this problem would be to [pipe](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection) the output from `grep` to [`cut`](https://thedatamine.github.io/the-examples-book/unix.html#cut).*

**Relevant topics:** *[cut](https://thedatamine.github.io/the-examples-book/unix.html#cut), [grep](https://thedatamine.github.io/the-examples-book/unix.html#grep)*

```{block, type="bbox"}
**Item(s) to submit:**

- The line of UNIX commands used to perform the operation.
```

##### 3. This particular dataset happens to be very small. You could imagine a scenario where the file is many gigabytes and not easy to load completely into R or Python. We are interested in learning what makes Jim and Pam tick as a couple. Use a line of UNIX commands to create a new dataset called `jim_and_pam.csv`. Include only lines that are spoken by either Jim or Pam, or reference Jim or Pam in any way. Include only the following columns: `episode_name`, `character`, `text`, `text_w_direction`, and `air_date`. How many rows of data are in the new file? How many megabytes is the new file (to the nearest 1/10th of a megabyte)?

**Hint:** *[Redirection](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection).*

**Hint:** *It is OK if you get an erroneous line where the word "jim" or "pam" appears as a part of another word.*

**Relevant topics:** *[cut](https://thedatamine.github.io/the-examples-book/unix.html#cut), [grep](https://thedatamine.github.io/the-examples-book/unix.html#grep), [ls](https://thedatamine.github.io/the-examples-book/unix.html#ls), [wc](https://thedatamine.github.io/the-examples-book/unix.html#wc), [redirection](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection)*

```{block, type="bbox"}
**Item(s) to submit:**

- The line of UNIX commands used to create the new file. 
- The number of rows of data in the new file, and the accompanying UNIX command used to find this out.
- The number of megabytes (to the nearest 1/10th of a megabyte) that the new file has, and the accompanying UNIX command used to find this out.
```

##### 4. Find all lines where either Jim/Pam/Michael/Dwight's name is followed by an exclamation mark. Use only 1 "!" within your regular expression. How many lines are there?

**Relevant topics:** *[grep](https://thedatamine.github.io/the-examples-book/unix.html#grep)*

```{block, type="bbox"}
**Item(s) to submit:**

- The UNIX command(s) used to solve this problem.
- The number of lines where either Jim/Pam/Michael/Dwight's name is followed by an exclamation mark.
```

##### 5. Find all lines that contain the text "that's what" followed by any amount of any text and then "said". How many lines are there?

**Relevant topics:** *[grep](https://thedatamine.github.io/the-examples-book/unix.html#grep)*

```{block, type="bbox"}
**Item(s) to submit:**

- The UNIX command used to solve this problem.
- The number of lines that contain the text "that's what" followed by any amount of text and then "said".
```

Regular expressions are really a useful semi language-agnostic tool. What this means is regardless of the programming language your are using, there will be some package that allows you to use regular expressions. In fact, we can use them in both R and Python! This can be particularly useful when dealing with strings. Load up the dataset you discovered in (1) using `read.csv`. Name the resulting data.frame `dat`.

##### 6. The `text_w_direction` column in `dat` contains the characters' lines with inserted direction that helps characters know what to do as they are reciting the lines. Direction is shown between square brackets "[" "]". Create a new column called `has_direction` that is set to `TRUE` if the `text_w_direction` column has direction, and `FALSE` otherwise. Use regular expressions and the `grepl` function in R to accomplish this.

**Hint:** *Make sure all opening brackets "[" have a corresponding closing bracket "]".*

**Hint:** *Think of the pattern as any line that has a [, followed by any amount of any text, followed by a ], followed by any amount of any text.*

**Relevant topics:** *[grep](https://thedatamine.github.io/the-examples-book/unix.html#grep), [grepl](#r-grep)*

```{block, type="bbox"}
**Item(s) to submit:**

- The R code used to solve this problem.
```

##### 7. Modify your regular expression in (7) to find lines with 2 or more sets of direction.

For example, the following line has 2 directions: `dat$text_w_direction[2789]`. How many lines have more than 2 directions? How many have more than 5?

```{txt}
This is a line with [emphasize this] only 1 direction!
This is a line with [emphasize this] 2 sets of direction, do you see the difference [shrug].
```

In (6), your solution may have found a match in both lines. In this question we want it to find only lines with 2+ directions, so the first line would not be a match.

**Relevant topics:** *[length](#r-length), [grep](#r-grep)*

```{block, type="bbox"}
**Item(s) to submit:**

- The R code used to solve this problem.
- How many lines have > 2 directions?
- How many lines have > 5 directions?
```

##### 8. Use the `str_extract_all` function from the `stringr` package to extract the direction(s) as well as the text between direction(s) from each line. Put the strings in a new column called `direction`.

```{txt}
This is a line with [emphasize this] only 1 direction!
This is a line with [emphasize this] 2 sets of direction, do you see the difference [shrug].
```

In this question, your solution may have extracted:

```{txt}
[emphasize this]
[emphasize this] 2 sets of direction, do you see the difference [shrug]
```

This is ok.

**Note:** *If you capture text between two sets of direction, this is ok. For example, if we capture "[this] is a [test]" from "if we capture [this] is a [test]", this is ok.*

**Relevant topics:** *[str_extract_all](#r-str-extract)*

```{block, type="bbox"}
**Item(s) to submit:**

- The R code used to solve this problem.
```

---

### Project 5

---

**Motivation:** Becoming comfortable stringing together commands and getting used to navigating files in a terminal is important for every data scientist to do. By learning the basics of a few useful tools, you will have the ability to quickly understand and manipulate files in a way which is just not possible using tools like Microsoft Office, Google Sheets, etc.

**Context:** We've been using UNIX tools in a terminal to solve a variety of problems. In this project we will continue to solve problems by combining a variety of tools using a form of redirection called piping.

**Scope:** grep, regular expression basics, UNIX utilities, redirection, piping

**Learning objectives:**

```{block, type="bbox"}
- Use `cut` to section off and slice up data from the command line.
- Use piping to string UNIX commands together.
- Use `sort` and it's options to sort data in different ways.
- Use `head` to isolate _n_ lines of output.
- Use `wc` to summarize the number of lines in a file or in output.
- Use `uniq` to filter out non-unique lines.
- Use `grep` to search files effectively.
```


You can find useful examples that walk you through relevant material in The Examples Book:

https://thedatamine.github.io/the-examples-book

It is highly recommended to read through, search, and explore these examples to help solve problems in this project.

**Important note:** It is highly recommended that you use https://rstudio.scholar.rcac.purdue.edu/. Simply click on the link and login using your Purdue account credentials. Use another system at your own risk. The version of RStudio on https://desktop.scholar.rcac.purdue.edu/ (which uses ThinLinc), is 99.9.9, and is known to have some strange issues when running code chunks.

Don't forget the very useful documentation shortcut `?`. To use, simply type `?` in the console, followed by the name of the function you are interested in. 

You can also look for package documentation by using `help(package=PACKAGENAME)`, so for example, to see the documentation for the package `ggplot2`, we could run:

```{r, eval=F}
help(package=ggplot2)
```

Sometimes it can be helpful to see the source code of a defined function. A [function](https://www.tutorialspoint.com/r/r_functions.htm) is any chunk of organized code that is used to perform an operation. Source code is the underlying `R` or `c` or `c++` code that is used to create the function. To see the source code of a defined function, type the function's name without the `()`. For example, if we were curious about what the function `Reduce` does, we could run:

```{r, eval=F}
Reduce
```

Occasionally this will be less useful as the resulting code will be code that calls `c` code we can't see. Other times it will allow you to understand the function better.

#### Dataset

The following questions will use the dataset found in Scholar:

`/class/datamine/data/amazon/amazon_fine_food_reviews.csv`

A public sample of the data can be found here: [amazon_fine_food_reviews.csv](https://www.datadepot.rcac.purdue.edu/datamine/amazon/amazon_fine_food_reviews.csv)

Answers to questions should all be answered using the full dataset located on Scholar. You may use the public samples of data to experiment with your solutions prior to running them using the full dataset.

#### Questions

##### 1. What is the `Id` of the most helpful review if we consider the review with highest `HelpfulnessNumerator` to be an indicator of helpfulness (higher is more helpful)?

**Relevant topics:** *[cut](https://thedatamine.github.io/the-examples-book/unix.html#cut), [sort](https://thedatamine.github.io/the-examples-book/unix.html#sort), [head](https://thedatamine.github.io/the-examples-book/unix.html#head), [piping](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection)*

```{block, type="bbox"}
**Item(s) to submit:**

- Line of UNIX commands used to solve the problem.
- The `Id` of the most helpful review.
```

##### 2. What proportion of all `Summary`s are unique? Use two lines of UNIX commands to find the answer.

**Relevant topics:** *[cut](https://thedatamine.github.io/the-examples-book/unix.html#cut), [uniq](https://thedatamine.github.io/the-examples-book/unix.html#uniq), [sort](https://thedatamine.github.io/the-examples-book/unix.html#sort), [wc](https://thedatamine.github.io/the-examples-book/unix.html#wc), [piping](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection)*

```{block, type="bbox"}
**Item(s) to submit:**

- Two lines of UNIX commands used to solve the problem.
- The ratio of unique `Summary`'s.
```

##### 3. Use a simple UNIX command to create a frequency table of `Score`.

**Relevant topics:** *[cut](https://thedatamine.github.io/the-examples-book/unix.html#cut), [uniq](https://thedatamine.github.io/the-examples-book/unix.html#uniq), [sort](https://thedatamine.github.io/the-examples-book/unix.html#sort), [piping](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection)*

```{block, type="bbox"}
**Item(s) to submit:**

- The line of UNIX commands used to solve the problem.
- The frequency table.
```

##### 4. Who is the user with the highest number of reviews? There are two columns you could use to answer this question, but which column do you think would be most appropriate and why?

**Hint:** *You may need to pipe the output to `sort` multiple times.*

**Hint:** *To create the frequency table, read through the `man` pages for `uniq`. Man pages are the "manual" pages for UNIX commands. You can read through the man pages for uniq by running the following:*

```{bash, eval=F}
man uniq
```

**Relevant topics:** *[cut](https://thedatamine.github.io/the-examples-book/unix.html#cut), [uniq](https://thedatamine.github.io/the-examples-book/unix.html#uniq), [sort](https://thedatamine.github.io/the-examples-book/unix.html#sort), [head](https://thedatamine.github.io/the-examples-book/unix.html#head), [piping](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection), [man](https://thedatamine.github.io/the-examples-book/unix.html#man)*

```{block, type="bbox"}
**Item(s) to submit:**

- The line of UNIX commands used to solve the problem.
- The frequency table.
```

##### 5. Anecdotally, there seems to be a tendency to leave reviews when we feel strongly (either positive or negative) about a product. For the user with the highest number of reviews, would you say that they follow this pattern of extremes? Let's consider 5 star reviews to be strongly positive and 1 star reviews to be strongly negative. Let's consider anything in between neither strongly positive nor negative.

**Hint:** *You may find the solution to problem (3) useful.*

**Relevant topics:** *[cut](https://thedatamine.github.io/the-examples-book/unix.html#cut), [uniq](https://thedatamine.github.io/the-examples-book/unix.html#uniq), [sort](https://thedatamine.github.io/the-examples-book/unix.html#sort), [grep](https://thedatamine.github.io/the-examples-book/unix.html#grep), [piping](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection)*

```{block, type="bbox"}
**Item(s) to submit:**

- The line of UNIX commands used to solve the problem.
```

##### 6. We want to compare the most helpful review with a `Score` of 5 with the most helpful review with a `Score` of 1. Use UNIX commands to calculate these values. Write down the `ProductId` of both reviews. In the case of a tie, write down all `ProductId`'s to get full credit. In this case we are considering the most helpful review to be the review with the highest `HelpfulnessNumerator`.

**Hint:** *You can use multiple lines to solve this problem.*

**Relevant topics:** *[sort](https://thedatamine.github.io/the-examples-book/unix.html#sort), [head](https://thedatamine.github.io/the-examples-book/unix.html#head), [piping](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection)*

```{block, type="bbox"}
**Item(s) to submit:**

- The lines of UNIX commands used to solve the problem.
- `ProductId`'s of both requested reviews.
```

##### 7. Using the `ProductId`'s from the previous question, create a new dataset called `reviews.csv` which contains the `ProductId`'s and `Score` of all reviews with the corresponding `ProductId`'s. 

**Relevant topics:** *[grep](https://thedatamine.github.io/the-examples-book/unix.html#head), [redirection](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection)*

```{block, type="bbox"}
**Item(s) to submit:**

- The line of UNIX commands used to solve the problem.
```

##### 8. Use R to load up `reviews.csv` into a new data.frame called `dat`. Create a histogram for each products' `Score`. Compare the most helpful review `Score` with the `Score`'s given in the histogram. Based on this comparison, decide (anecdotally) whether you think people found the review helpful because the product is overrated, underrated, or correctly reviewed by the masses.

**Relevant topics:** *[read.csv](file:///Users/kamstut/Dropbox/work/datamine/the-examples-book/docs/r.html#r-reading-and-writing-data), [hist](file:///Users/kamstut/Dropbox/work/datamine/the-examples-book/docs/r.html#r-plotting)*

```{block, type="bbox"}
**Item(s) to submit:**

- R code used to create the histograms.
- 3 histograms, 1 for each `ProductId`.
- 1-2 sentences explaining whether or not you think people found the review helpful because the produce is overrated, underrated, or correctly reviewed, and why.
```

---

### Project 6

---

**Motivation:** A bash script is a powerful tool to perform repeated tasks. RCAC uses bash scripts to automate a variety of tasks. In fact, we use bash scripts on Scholar to do things like link Python kernels to your account, fix potential isues with Firefox, etc. `awk` is a programming language designed for text processing. The combination of these tools can be really powerful and useful for a variety of quick tasks.

**Context:** This is the first part in a series of projects that are designed to exercise skills around UNIX utilities, with a focus on writing bash scripts and `awk`. You will get the opportunity to manipulate data without leaving the terminal. At first it may seem overwhelming, however, with just a little practice you will be able to accomplish data wrangling tasks really efficiently. 

**Scope:** awk, UNIX utilities, bash scripts

**Learning objectives:**

```{block, type="bbox"}
- Use `awk` to process and manipulate textual data.
- Use piping and redirection within the terminal to pass around data between utilities.
```

#### Dataset: 

The following questions will use the dataset found [here](https://www.datadepot.rcac.purdue.edu/datamine/flights/subset/YYYY.csv) or in Scholar:

`/class/datamine/data/flights/subset/YYYY.csv` 

An example from 1987 data can be found [here](https://www.datadepot.rcac.purdue.edu/datamine/flights/subset/1987.csv) or in Scholar:

`/class/datamine/data/flights/subset/1987.csv`

#### Questions 

##### 1. In previous projects we learned how to get a single column of data from a csv file. Write 1 line of UNIX commands to print the 17th column, the `Origin`, from `1987.csv`. Write another line, this time using `awk` to do the same thing. Which one do you prefer, and why?

**Relevant topics:** [cut](#cut), [awk](#awk)

```{block, type="bbox"}
**Item(s) to submit:**

- One line of UNIX commands to solve the problem *without* using `awk`.
- One line of UNIX commands to solve the problem using `awk`.
- 1-2 sentences describing which method you prefer and why.
```

##### 2. Write a bash script that accepts a year (1987, 1988, etc.) and a column *n* and returns the *nth* column of the associated year of data.

**Relevant topics:** [awk](#awk), [bash scripts](#writing-scripts)

```{block, type="bbox"}
**Item(s) to submit:**

- The content of your bash script (starting with "#!/bin/bash") in a code chunk.
```

##### 3. How many flights came into Indianapolis (IND) in 2008? First solve this problem without using `awk`, then solve this problem using *only* `awk`.

**Relevant topics:** [cut](#cut), [grep](#grep), [wc](#wc), [awk](#awk), [piping](#piping-and-redirection)

```{block, type="bbox"}
**Item(s) to submit:** 

- One line of UNIX commands to solve the problem *without* using `awk`.
- One line of  UNIX commands to solve the problem using `awk`. 
- The number of flights that came into Indianapolis (IND) in 2008.
```

##### 4. Do you expect the number of unique origins and destinations to be the same? Find out using any command line tool you'd like. Are they indeed the same? How many unique values do we have per category (`Origin`, `Dest`)?

**Relevant topics:** [cut](#cut), [sort](#sort), [uniq](#uniq), [wc](#wc), [awk](#awk)

```{block, type="bbox"}
**Item(s) to submit:**

- 1-2 sentences explaining whether or not you expect the number of unique origins and destinations to be the same.
- The UNIX command(s) used to figure out if the number of unique origins and destinations are the same. 
- The number of unique values per category (`Origin`, `Dest`).
```

##### 5. In (4) we found that there are not the same number of unique `Origin`'s as `Dest`'s. Find the IATA airport code for all `Origin`'s that dont appear in a `Dest` and all `Dest`'s that don't appear in an `Origin`.

**Hint:** https://www.tutorialspoint.com/unix_commands/comm.html

**Relevant topics:** [comm](#unix), [cut](#cut), [sort](#sort), [uniq](#uniq), [redirection](#piping-and-redirection)

```{block, type="bbox"}
**Item(s) to submit:**

- The line(s) of UNIX command(s) used to answer the question.
- The list of `Origin`s that don't appear in `Dest`.
- The list of `Dest`s that don't appear in `Origin`.
```


##### 6. What was the average number of flights in 2008 per unique `Origin` with the `Dest` of "IND"? How does "PHX" (as a unique `Origin`) compare to the average?

**Hint:** You manually do the average calculation by dividing the result from (3) by the number of unique `Origin`'s that have a `Dest` of "IND".

**Relevant topics:** [awk](#awk), [sort](#sort), [grep](#grep), [wc](#wc)

```{block, type="bbox"}
**Item(s) to submit:**

- The average number of flights in 2008 per unique `Origin` with the `Dest` of "IND".
- 1-2 sentences explaining how "PHX" compares (as a unique `Origin`) to the average?
```

##### 7. Write a bash script that takes a year and IATA airport code and returns the year, and the total number of flights to and from the given airport. Example rows may look like:

```{txt, eval=F}
1987, 12345
1988, 44
```

Run the script with inputs: `1991` and `ORD`. Include the output in your submission.

**Relevant topics:** [bash scripts](#writing-scripts), [cut](#cut), [piping](#piping-and-redirection), [grep](#grep), [wc](#wc)

```{block, type="bbox"}
**Item(s) to submit:**

- The content of your bash script (starting with "#!/bin/bash") in a code chunk.
- The output of the script given `1991` and `ORD` as inputs.
```

---

### Project 7

---

**Motivation:** A bash script is a powerful tool to perform repeated tasks. RCAC uses bash scripts to automate a variety of tasks. In fact, we use bash scripts on Scholar to do things like link Python kernels to your account, fix potential isues with Firefox, etc. `awk` is a programming language designed for text processing. The combination of these tools can be really powerful and useful for a variety of quick tasks.

**Context:** This is the first part in a series of projects that are designed to exercise skills around UNIX utilities, with a focus on writing bash scripts and `awk`. You will get the opportunity to manipulate data without leaving the terminal. At first it may seem overwhelming, however, with just a little practice you will be able to accomplish data wrangling tasks really efficiently. 

**Scope:** awk, UNIX utilities, bash scripts

**Learning objectives:**

```{block, type="bbox"}
- Use `awk` to process and manipulate textual data.
- Use piping and redirection within the terminal to pass around data between utilities.
```

#### Dataset: 

The following questions will use the dataset found in Scholar:
`/class/datamine/data/flights/subset/YYYY.csv` 

An example of the data for the year 1987 can be found [here](https://www.datadepot.rcac.purdue.edu/datamine/flights/subset/1987.csv).

Sometimes if you are about to dig into a dataset, it is good to quickly do some sanity checks early on to make sure the data is what you expect it to be. 

##### 1. Write a line of code that prints a list of the unique values in the `DayOfWeek` column. Write a line of code that prints a list of the unique values in the `DayOfMonth` column. Write a line of code that prints a list of the unique values in the `Month` column. Use the `1987.csv` dataset. Are the results what you expected?

**Relevant topics:** [cut](#cut), [sort](#sort)

```{block, type="bbox"}
**Item(s) to submit:**

- 3 lines of code used to get a list of unique values for the chosen columns.
- 1-2 sentences explaining whether or not the results are what you expected.
```

##### 2. Our files should have 29 columns. Write a line of code that prints any lines in a file that do *not* have 29 columns. Test it on `1987.csv`, were there any rows without 29 columns?

**Relevant topics:** [awk](#awk)

```{block, type="bbox"}
**Item(s) to submit:**

- Line of code used to solve the problem.
- 1-2 sentences explaining whether or not there were any rows without 29 columns.
```

##### 3. Write a bash script that, given a "begin" year and "end" year, cycles through the associated files and prints any lines that do *not* have 29 columns.

**Relevant topics:** [awk](#awk), [bash scripts](#writing-scripts)

```{block, type="bbox"}
**Item(s) to submit:**

- The content of your bash script (starting with "#!/bin/bash") in a code chunk.
- The results of running your bash scripts from year 1987 to 2008.
```

##### 4. `awk` is a really good tool to quickly get some data and manipulate it a little bit. For example, let's see the number of kilometers and miles traveled in 1990. To convert from miles to kilometers, simply multiply by 1.609344. 

**Example output:**

```{txt, eval=F}
Miles: 12345
Kilometers: 19867.35168
```

**Relevant topics:** [awk](#awk), [piping](#piping-and-redirection)

```{block, type="bbox"}
**Item(s) to submit:**

- The code used to solve the problem. 
- The results of running the code.
```

##### 5. Use `awk` to calculate the number of `DepDelay` minutes by `DayOfWeek`. Use `2007.csv`.

**Example output:**

```{txt, eval=F}
DayOfWeek:  0
1:  1234567
2:  1234567
3:  1234567
4:  1234567
5:  1234567
6:  1234567
7:  1234567
```

**Note:** 1 is Monday.

**Relevant topics:** [awk](#awk), [sort](#sort), [piping](#piping-and-redirection)

```{block, type="bbox"}
**Item(s) to submit:**

- The code used to solve the problem.
- The output from running the code.
```

##### 6. It wouldn't be fair to compare the total `DepDelay` minutes by `DayOfWeek` as the number of flights may vary. One way to take this into account is to instead calculate an average. Modify (5) to calculate the average number of `DepDelay` minutes by the number of flights per `DayOfWeek`. Use `2007.csv`.

**Example output:**

```{txt, eval=F}
DayOfWeek:  0
1:  1.234567
2:  1.234567
3:  1.234567
4:  1.234567
5:  1.234567
6:  1.234567
7:  1.234567
```

**Relevant topics:** [awk](#awk), [sort](#sort), [piping](#piping-and-redirection)

```{block, type="bbox"}
**Item(s) to submit:**

- The code used to solve the problem.
- The output from running the code.
```

##### 7. As a quick follow-up, _slightly_ modify (6) to perform the same calculation for `ArrDelay`. Do the `ArrDelay`s and `DepDelay`s appear to have the highest delays on the same day? Use `2007.csv`.

**Example output:**

```{txt, eval=F}
DayOfWeek:  0
1:  1.234567
2:  1.234567
3:  1.234567
4:  1.234567
5:  1.234567
6:  1.234567
7:  1.234567
```

**Relevant topics:** [awk](#awk), [sort](#sort), [piping](#piping-and-redirection)

```{block, type="bbox"}
**Item(s) to submit:**

- The code used to solve the problem.
- The output from running the code.
- 1-2 sentences explaining whether or not the `ArrDelay`s and `DepDelay`s appear to have the highest delays on the same day.
```

---

### Project 8

---

**Motivation:** A bash script is a powerful tool to perform repeated tasks. RCAC uses bash scripts to automate a variety of tasks. In fact, we use bash scripts on Scholar to do things like link Python kernels to your account, fix potential isues with Firefox, etc. `awk` is a programming language designed for text processing. The combination of these tools can be really powerful and useful for a variety of quick tasks.

**Context:** This is the first part in a series of projects that are designed to exercise skills around UNIX utilities, with a focus on writing bash scripts and `awk`. You will get the opportunity to manipulate data without leaving the terminal. At first it may seem overwhelming, however, with just a little practice you will be able to accomplish data wrangling tasks really efficiently. 

**Scope:** awk, UNIX utilities, bash scripts

**Learning objectives:**

```{block, type="bbox"}
- Use `awk` to process and manipulate textual data.
- Use piping and redirection within the terminal to pass around data between utilities.
```

#### Dataset: 

The following questions will use the dataset found in Scholar:
`/class/datamine/data/flights/subset/YYYY.csv` 

An example of the data for the year 1987 can be found [here](https://www.datadepot.rcac.purdue.edu/datamine/flights/subset/1987.csv).


Let's say we have a theory that there are more flights on the weekend days (Friday, Saturday, Sunday) than the rest of the days, on average. We can use awk to quickly check it out and see if maybe this looks like something that is true!

##### 1. Write a line of `awk` code that, prints the number of flights on the weekend days, followed by the number of flights on the weekdays for the flights during 2008.

**Relevant topics:** [awk](#awk)

```{block, type="bbox"}
**Item(s) to submit:**

- Line of `awk` code that solves the problem.
- The result: the number of flights on the weekend days, followed by the number of flights on the weekdays for the flights during 2008.
```

##### 2. Note that in (1), we are comparing 3 days to 4! Write a line of `awk` code that, prints the average number of flights on a weekend day, followed by the average number of flights on the weekdays. Continue to use data for 2008.

**Relevant topics:** [awk](#awk)

```{block, type="bbox"}
**Item(s) to submit:**

- Line of `awk` code that solves the problem.
- The result: the average number of flights on the weekend days, followed by the average number of flights on the weekdays for the flights during 2008.
```

We want to look to see if there may be some truth to the whole "snow bird" concept where people will travel to warmer states like Florida and Arizona during the Winter. Let's use the tools we've learned to explore this a little bit. 

##### 3. Take a look at `airports.csv`. In particular run the following:

```{bash, eval=F}
head airports.csv
```

Notice how all of the non-numeric text is surrounded by quotes. The surrounding quotes would need to be escaped for any comparison within `awk`. This is messy and we would prefer to create a new file called `new_airports.csv` without any quotes. Write a line of code to do this. 

**Hint:** You could use `gsub` within `awk` to replace '"' with ''.

**Hint:** If you leave out the column number argument to `gsub` it will apply the substitution to every field in every column.

**Relevant topics:** [awk](#awk), [redirection](#piping-and-redirection)

```{block, type="bbox"}
**Item(s) to submit:**

- Line of `awk` code used to create the new dataset.
```

##### 4. Write a line of commands that create a new dataset called `az_fl_airports.txt` that contains a list of airport codes for all airports from both Arizona (AZ) and Florida (FL). Use the file we created in (3),`new_airports.csv`.

**Relevant topics:** [awk](#awk)

```{block, type="bbox"}
**Item(s) to submit:**

- The line of UNIX commands to create an array called `airports`.
```

##### 5. Wow! In (4) we discovered a lot of airports! How many airports are there? Did you expect this? Use a line of bash code to answer this question.

**Relevant topics:** [echo](#echo), [wc](#wc), [piping](#piping-and-redirection)

```{block, type="bbox"}
**Item(s) to submit:**

- Line of UNIX commands used to solve the problem.
- The number of airports.
- 1-2 sentences explaining whether you expected this result and why or why not.
```

##### 6. Create a new dataset that contains all of the data for flights into or out of Florida and Arizona using 2008.csv, use the newly created dataset, `az_fl_airports.txt` in (4) to do so.

**Hint:** https://unix.stackexchange.com/questions/293684/basic-grep-awk-help-extracting-all-lines-containing-a-list-of-terms-from-one-f

**Relevant topics:** [grep](#grep)

```{block, type="bbox"}
**Item(s) to submit:**

- Line of UNIX commands used to solve the problem.
```

##### 7. Now that you have code to complete (6), write a bash script that accepts the start year, end year, and filename containing airport codes (`az_fl_airports.txt`), and outputs the data for flights into or out of any of the airports listed in the provided filename containing airport codes using _all_ of the years of data in the provided range. Run the bash script to create a new file called `az_fl_flights.csv`.

**Relevant topics:** [bash scripts](#writing-scripts), [grep](#grep), for loop, [redirection](#redirection)

```{block, type="bbox"}
**Item(s) to submit:**

- The content of your bash script (starting with "#!/bin/bash") in a code chunk.
- The line of UNIX code you used to execute the script and create the new dataset.
```

---

## STAT 39000

### Project 2

---

**Motivation:** The ability to quickly reproduce an analysis is important. It is often necessary that other individuals will need to be able to understand and reproduce an analysis. This concept is so important there are classes solely on reproducible research! In fact, there are papers that investigate and highlight the lack of reproducibility in various fields. If you are interested in reading about this topic, a good place to start is the paper titled ["Why Most Published Research Findings Are False"](https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124), by John Ioannidis (2005). 

**Context:** Making your work reproducible is extremely important. We will focus on the computational part of reproducibility. We will learn RMarkdown to document your analyses so others can easily understand and reproduce the computations that led to your conclusions. Pay close attention as future project templates will be RMarkdown templates.

**Scope:** Understand Markdown, RMarkdown, and how to use it to make your data analysis reproducible.

**Learning objectives:**

```{block, type="bbox"}
- Use Markdown syntax within an Rmarkdown document to achieve various text transformations.
- Use RMarkdown code chunks to display and/or run snippets of code.
```


You can find useful examples that walk you through relevant material in The Examples Book:

https://thedatamine.github.io/the-examples-book

It is highly recommended to read through, search, and explore these examples to help solve problems in this project.

**Important note:** It is highly recommended that you use https://rstudio.scholar.rcac.purdue.edu/. Simply click on the link and login using your Purdue account credentials. Use another system at your own risk. The version of RStudio on https://desktop.scholar.rcac.purdue.edu/ (which uses ThinLinc), is 99.9.9, and is known to have some strange issues when running code chunks.

Don't forget the very useful documentation shortcut `?`. To use, simply type `?` in the console, followed by the name of the function you are interested in. 

You can also look for package documentation by using `help(package=PACKAGENAME)`, so for example, to see the documentation for the package `ggplot2`, we could run:

```{r, eval=F}
help(package=ggplot2)
```

Sometimes it can be helpful to see the source code of a defined function. A [function](https://www.tutorialspoint.com/r/r_functions.htm) is any chunk of organized code that is used to perform an operation. Source code is the underlying `R` or `c` or `c++` code that is used to create the function. To see the source code of a defined function, type the function's name without the `()`. For example, if we were curious about what the function `Reduce` does, we could run:

```{r, eval=F}
Reduce
```

Occasionally this will be less useful as the resulting code will be code that calls `c` code we can't see. Other times it will allow you to understand the function better.

##### 1. Make the following text (including the asterisks) bold: `This needs to be **very** bold`. Make the following text (including the underscores) italicized: `This needs to be _very_ italicized.`

**Hint:** *Try mixing and matching ways to embolden or italicize text. Alternatively, look up "escaping characters in markdown", or see [here](https://thedatamine.github.io/the-examples-book/faqs.html#escape-characters).*

**Hint:** *Be sure to check out the [Rmarkdown Cheatsheet](https://rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf) and our section on [Rmarkdown in the book](https://thedatamine.github.io/the-examples-book/r.html#r-rmarkdown).*

**Note:** *Rmarkdown is essentially Markdown + the ability to run and display code chunks. In this question, we are actually using Markdown within Rmarkdown!*

**Relevant topics:** *[rmarkdown](https://thedatamine.github.io/the-examples-book/r.html#r-rmarkdown), [escaping characters](https://thedatamine.github.io/the-examples-book/faqs.html#escape-characters)*

```{block, type="bbox"}
**Item(s) to submit:**

- Fill in the chunk under (1) in the `stat29000project02template.Rmd` file with 2 lines of markdown text. Note that when compiled, this text will be unmodified, regular text.
```

##### 2. Create an unordered list of your top 3 favorite academic interests (some examples could include: machine learning, operating systems, forensic accounting, etc.). Create another *ordered* list that ranks your academic interests in order of most interested to least interested.

**Hint:** *You can learn what ordered and unordered lists are [here]( https://rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf).*

**Note:** *Similar to (1a), in this question we are dealing with Markdown. If we were to copy and paste the solution to this problem in a Markdown editor, it would be the same result as when we Knit it here.*

**Relevant topics:** *[rmarkdown](https://thedatamine.github.io/the-examples-book/r.html#r-rmarkdown)*

```{block, type="bbox"}
**Item(s) to submit:**

- Create the lists under (2) in the `stat29000project02template.Rmd` file. Note that when compiled, this text will appear as nice, formatted lists.
```

##### 3. Browse https://www.linkedin.com/ and read some profiles. Pay special attention to accounts with an "About" section. Write your own personal "About" section using Markdown. Include the following:

- A header (your choice of size) that says "About".
- A horizontal rule directly underlining the header.
- The text of your personal "About" section that you would feel comfortable uploading to linkedin, including at least 1 link.

**Relevant topics:** *[rmarkdown](https://thedatamine.github.io/the-examples-book/r.html#r-rmarkdown)*

```{block, type="bbox"}
**Item(s) to submit:**

- Create the described profile under (3) in the `stat29000project02template.Rmd` file.
```

##### 4. LaTeX is a powerful editing tool where you can create beautifully formatted equations and formulas. Replicate the equation found [here](https://wikimedia.org/api/rest_v1/media/math/render/svg/87c061fe1c7430a5201eef3fa50f9d00eac78810) as closely as possible.

**Hint:** *Lookup "latex mid" and "latex frac".*

```{block, type="bbox"}
**Item(s) to submit:**

- Replicate the equation using LaTeX under (1d) in the `stat39000project02template.Rmd` file.
```

##### 5. Your co-worker wrote a report, and has asked you to beautify it. Knowing Rmarkdown, you agreed. Spruce up the report found under (4) in `stat29000project02template.Rmd`. At a minimum:

- Make the title pronounced.
- Make all links appear as a word or words, rather than the long-form URL.
- Organize all code into code chunks where code and output are displayed. If the output is really long, just display the code.
- Make the calls to the `library` function and the `install.packages` function be evaluated but not displayed. Make sure all warnings and errors that may eventually occur, do not appear in the final document.

Feel free to make any other changes that make the report more visually pleasing.

**Relevant topics:** *[rmarkdown](https://thedatamine.github.io/the-examples-book/r.html#r-rmarkdown)*

```{block, type="bbox"}
**Item(s) to submit:**

- Spruce up the "document" under (4) in the `stat29000project02template.Rmd` file.
```

#### 6. Create a plot using a built-in dataset like `iris`, `mtcars`, or `Titanic`, and display the plot using a code chunk. Make sure the code used to generate the plot is hidden. Include a descriptive caption for the image.

**Relevant topics:** *[rmarkdown](https://thedatamine.github.io/the-examples-book/r.html#r-rmarkdown), [plotting in r](https://thedatamine.github.io/the-examples-book/r.html#r-plotting)*

```{block, type="bbox"}
**Item(s) to submit:**

- Code chunk under (5) that creates and displays a plot using a built-in dataset like `iris`, `mtcars`, or `Titanic`.
```

##### 7. Insert the following code chunk under (5) in `stat29000project02template.Rmd`. Try knitting the document. Something should go wrong. Fix the problem and knit again. If another problem appears, fix it. What was the first problem? What was the second problem?
       
````markdown
`r ''````{r install-packages}
plot(my_variable)
```
````

**Hint:** *Take a close look at the name we give our code chunk.*

**Hint:** *Take a look at the code chunk where `my_variable` is declared.*

**Relevant topics:** *[rmarkdown](https://thedatamine.github.io/the-examples-book/r.html#r-rmarkdown)*

```{block, type="bbox"}
**Item(s) to submit:**

- The modified version of the inserted code that fixes both problems.
- A sentence explaining what the first problem was.
- A sentence explaining what the second problem was.
```

##### 8. RMarkdown is also an excellent tool to create a slide deck. Use the information [here](https://rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf) or [here](https://thedatamine.github.io/the-examples-book/r.html#how-do-i-create-a-set-of-slides-using-rmarkdown) to convert your solutions into a slide deck rather than the regular PDF. You may use `slidy`, `ioslides` or `beamer`. Make any needed modifications to make the solutions knit into a well-organized slide deck. Modify (2) so the bullets are incrementally presented as the slides progresses.

**Relevant topics:** *[rmarkdown](https://thedatamine.github.io/the-examples-book/r.html#r-rmarkdown)*

```{block, type="bbox"}
**Item(s) to submit:**

- The modified version of the inserted code that fixes both problems.
- A sentence explaining what the first problem was.
- A sentence explaining what the second problem was.
```

---

### Project 4

---

**Motivation:** The need to search files and datasets based on the text held within is common during various parts of the data wrangling process. `grep` is an extremely powerful UNIX tool that allows you to do so using regular expressions. Regular expressions are a structured method for searching for specified patterns. Regular expressions can be very complicated, [even professionals can make critical mistakes](https://blog.cloudflare.com/details-of-the-cloudflare-outage-on-july-2-2019/). With that being said, learning some of the basics is an incredible tool that will come in handy regardless of the language you are working in.

**Context:** We've just begun to learn the basics of navigating a file system in UNIX using various terminal commands. Now we will go into more depth with one of the most useful command line tools, `grep`, and experiment with regular expressions using `grep`, R, and later on, Python.

**Scope:** grep, regular expression basics, utilizing regular expression tools in R and Python

**Learning objectives:**

```{block, type="bbox"}
- Use `grep` to search for patterns within a dataset.
- Use `cut` to section off and slice up data from the command line.
- Use `wc` to count the number of lines of input.
```


You can find useful examples that walk you through relevant material in The Examples Book:

https://thedatamine.github.io/the-examples-book

It is highly recommended to read through, search, and explore these examples to help solve problems in this project.

**Important note:** It is highly recommended that you use https://rstudio.scholar.rcac.purdue.edu/. Simply click on the link and login using your Purdue account credentials. Use another system at your own risk. The version of RStudio on https://desktop.scholar.rcac.purdue.edu/ (which uses ThinLinc), is 99.9.9, and is known to have some strange issues when running code chunks.

Don't forget the very useful documentation shortcut `?`. To use, simply type `?` in the console, followed by the name of the function you are interested in. 

You can also look for package documentation by using `help(package=PACKAGENAME)`, so for example, to see the documentation for the package `ggplot2`, we could run:

```{r, eval=F}
help(package=ggplot2)
```

Sometimes it can be helpful to see the source code of a defined function. A [function](https://www.tutorialspoint.com/r/r_functions.htm) is any chunk of organized code that is used to perform an operation. Source code is the underlying `R` or `c` or `c++` code that is used to create the function. To see the source code of a defined function, type the function's name without the `()`. For example, if we were curious about what the function `Reduce` does, we could run:

```{r, eval=F}
Reduce
```

Occasionally this will be less useful as the resulting code will be code that calls `c` code we can't see. Other times it will allow you to understand the function better.

#### Dataset

The following questions will use the dataset found in Scholar:

`/class/datamine/data/movies_and_tv/the_office_dialogue.csv`

A public sample of the data can be found here: [the_office_dialogue.csv](https://www.datadepot.rcac.purdue.edu/datamine/movies-and-tv/the_office_dialogue.csv)

Answers to questions should all be answered using the full dataset located on Scholar. You may use the public samples of data to experiment with your solutions prior to running them using the full dataset.

`grep` stands for (g)lobally search for a (r)egular (e)xpression and (p)rint matching lines. As such, to best demonstrate `grep`, we will be using it with textual data. You can read about and see examples of `grep` [here](https://thedatamine.github.io/the-examples-book/unix.html#grep).

##### 1. Login to Scholar and use `grep` to find the dataset we will use this project. The dataset we will use is the only dataset to have the text "bears. beets. battlestar galactica.". What is the name of the dataset and where is it located?

**Relevant topics:** *[grep](https://thedatamine.github.io/the-examples-book/unix.html#grep)*

```{block, type="bbox"}
**Item(s) to submit:**

- The `grep` command used to find the dataset.
- The name and location in Scholar of the dataset.
- Use `grep` and `grepl` within R to solve a data-driven problem.
```

##### 2. `grep` prints the line that the text you are searching for appears in. In project 3 we learned a UNIX command to quickly print the first _n_ lines from a file. Use this command to get the headers for the dataset. As you can see, each line in the tv show is a row in the dataset. You can count to see which column the various bits of data live in.

Write a line of UNIX commands that searches for "bears. beets. battlestar galactica." and, rather than printing the entire line, prints only the character who speaks the line, as well as the line itself.

**Hint:** *The result if you were to search for "bears. beets. battlestar galactica." should be:*

```{txt}
"Jim","Fact. Bears eat beets. Bears. Beets. Battlestar Galactica."
```

**Hint:** *One method to solve this problem would be to [pipe](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection) the output from `grep` to [`cut`](https://thedatamine.github.io/the-examples-book/unix.html#cut).*

**Relevant topics:** *[cut](https://thedatamine.github.io/the-examples-book/unix.html#cut), [grep](https://thedatamine.github.io/the-examples-book/unix.html#grep)*

```{block, type="bbox"}
**Item(s) to submit:**

- The line of UNIX commands used to perform the operation.
```

##### 3. This particular dataset happens to be very small. You could imagine a scenario where the file is many gigabytes and not easy to load completely into R or Python. We are interested in learning what makes Jim and Pam tick as a couple. Use a line of UNIX commands to create a new dataset called `jim_and_pam.csv`. Include only lines that are spoken by either Jim or Pam, or reference Jim or Pam in any way. Include only the following columns: `episode_name`, `character`, `text`, `text_w_direction`, and `air_date`. How many rows of data are in the new file? How many megabytes is the new file (to the nearest 1/10th of a megabyte)?

**Hint:** *[Redirection](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection).*

**Hint:** *It is OK if you get an erroneous line where the word "jim" or "pam" appears as a part of another word.*

**Relevant topics:** *[cut](https://thedatamine.github.io/the-examples-book/unix.html#cut), [grep](https://thedatamine.github.io/the-examples-book/unix.html#grep), [ls](https://thedatamine.github.io/the-examples-book/unix.html#ls), [wc](https://thedatamine.github.io/the-examples-book/unix.html#wc), [redirection](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection)*

```{block, type="bbox"}
**Item(s) to submit:**

- The line of UNIX commands used to create the new file. 
- The number of rows of data in the new file, and the accompanying UNIX command used to find this out.
- The number of megabytes (to the nearest 1/10th of a megabyte) that the new file has, and the accompanying UNIX command used to find this out.
```

##### 4. Find all lines where either Jim/Pam/Michael/Dwight's name is followed by an exclamation mark. Use only 1 "!" within your regular expression. How many lines are there?

**Relevant topics:** *[grep](https://thedatamine.github.io/the-examples-book/unix.html#grep)*

```{block, type="bbox"}
**Item(s) to submit:**

- The UNIX command(s) used to solve this problem.
- The number of lines where either Jim/Pam/Michael/Dwight's name is followed by an exclamation mark.
```

##### 5. Find all lines that contain the text "that's what" followed by any amount of any text and then "said". How many lines are there?

**Relevant topics:** *[grep](https://thedatamine.github.io/the-examples-book/unix.html#grep)*

```{block, type="bbox"}
**Item(s) to submit:**

- The UNIX command used to solve this problem.
- The number of lines that contain the text "that's what" followed by any amount of text and then "said".
```

##### 6. Find all of the lines where Pam is called "Beesley" instead of "Pam" or "Pam Beesley".

**Hint:** *A negative lookbehind would be one way to solve this.*

**Relevant topics:** *[grep](https://thedatamine.github.io/the-examples-book/unix.html#grep)*

```{block, type="bbox"}
**Item(s) to submit:**

- The UNIX command used to solve this problem.
```

Regular expressions are really a useful semi language-agnostic tool. What this means is regardless of the programming language your are using, there will be some package that allows you to use regular expressions. In fact, we can use them in both R and Python! This can be particularly useful when dealing with strings. Load up the dataset you discovered in (1) using `read.csv`. Name the resulting data.frame `dat`.

##### 7. The `text_w_direction` column in `dat` contains the characters' lines with inserted direction that helps characters know what to do as they are reciting the lines. Direction is shown between square brackets "[" "]". Create a new column called `has_direction` that is set to `TRUE` if the `text_w_direction` column has direction, and `FALSE` otherwise. Use regular expressions and the `grepl` function in R to accomplish this.

**Hint:** *Make sure all opening brackets "[" have a corresponding closing bracket "]".*

**Hint:** *Think of the pattern as any line that has a [, followed by any amount of any text, followed by a ], followed by any amount of any text.*

**Relevant topics:** *[grep](https://thedatamine.github.io/the-examples-book/unix.html#grep), [grepl](#r-grep)*

```{block, type="bbox"}
**Item(s) to submit:**

- The R code used to solve this problem.
```

##### 8. Modify your regular expression in (7) to find lines with 2 or more sets of direction.

For example, the following line has 2 directions: `dat$text_w_direction[2789]`. How many lines have more than 2 directions? How many have more than 5?

```{txt}
This is a line with [emphasize this] only 1 direction!
This is a line with [emphasize this] 2 sets of direction, do you see the difference [shrug].
```

In (7), your solution may have found a match in both lines. In this question we want it to find only lines with 2+ directions, so the first line would not be a match.

**Relevant topics:** *[length](#r-length), [grep](#r-grep)*

```{block, type="bbox"}
**Item(s) to submit:**

- The R code used to solve this problem.
- How many lines have > 2 directions?
- How many lines have > 5 directions?
```

##### 9. Use the `str_extract_all` function from the `stringr` package to extract the direction(s) as well as the text between direction(s) from each line. Put the strings in a new column called `direction`.

```{txt}
This is a line with [emphasize this] only 1 direction!
This is a line with [emphasize this] 2 sets of direction, do you see the difference [shrug].
```

In this question, your solution may have extracted:

```{txt}
[emphasize this]
[emphasize this] 2 sets of direction, do you see the difference [shrug]
```

This is ok.

**Note:** *If you capture text between two sets of direction, this is ok. For example, if we capture "[this] is a [test]" from "if we capture [this] is a [test]", this is ok.*

**Relevant topics:** *[str_extract_all](#r-str-extract)*

```{block, type="bbox"}
**Item(s) to submit:**

- The R code used to solve this problem.
```

##### 10. Repeat (9) but this time make sure you only capture the brackets and text within the brackets. Save the results in a new column called `direction_correct`. You can test to see if it is working by running the following code:

```{r, eval=F}
dat$direction_correct[747]
```

```{txt}
This is a line with [emphasize this] only 1 direction!
This is a line with [emphasize this] 2 sets of direction, do you see the difference [shrug].
```

In (7), your solution may have extracted:

```{txt}
[emphasize this]
[emphasize this] 2 sets of direction, do you see the difference [shrug]
```

This is ok for (7). In this question, however, we want to fix this to only extract:

```{txt}
[emphasize this]
[emphasize this] [shrug]
```

**Hint:** *This regular expression will be hard to read.*

**Hint:** *The pattern we want is: literal opening bracket, followed by 0+ of any character other than the literal [ or literal ], followed by a literal closing bracket.*

**Relevant topics:** *[str_extract_all](#r-str-extract)*

```{block, type="bbox"}
**Item(s) to submit:**

- The R code used to solve this problem.
```

---

### Project 5

---

**Motivation:** Becoming comfortable stringing together commands and getting used to navigating files in a terminal is important for every data scientist to do. By learning the basics of a few useful tools, you will have the ability to quickly understand and manipulate files in a way which is just not possible using tools like Microsoft Office, Google Sheets, etc.

**Context:** We've been using UNIX tools in a terminal to solve a variety of problems. In this project we will continue to solve problems by combining a variety of tools using a form of redirection called piping.

**Scope:** grep, regular expression basics, UNIX utilities, redirection, piping

**Learning objectives:**

```{block, type="bbox"}
- Use `cut` to section off and slice up data from the command line.
- Use piping to string UNIX commands together.
- Use `sort` and it's options to sort data in different ways.
- Use `head` to isolate _n_ lines of output.
- Use `wc` to summarize the number of lines in a file or in output.
- Use `uniq` to filter out non-unique lines.
- Use `grep` to search files effectively.
```

You can find useful examples that walk you through relevant material in The Examples Book:

https://thedatamine.github.io/the-examples-book

It is highly recommended to read through, search, and explore these examples to help solve problems in this project.

**Important note:** It is highly recommended that you use https://rstudio.scholar.rcac.purdue.edu/. Simply click on the link and login using your Purdue account credentials. Use another system at your own risk. The version of RStudio on https://desktop.scholar.rcac.purdue.edu/ (which uses ThinLinc), is 99.9.9, and is known to have some strange issues when running code chunks.

Don't forget the very useful documentation shortcut `?`. To use, simply type `?` in the console, followed by the name of the function you are interested in. 

You can also look for package documentation by using `help(package=PACKAGENAME)`, so for example, to see the documentation for the package `ggplot2`, we could run:

```{r, eval=F}
help(package=ggplot2)
```

Sometimes it can be helpful to see the source code of a defined function. A [function](https://www.tutorialspoint.com/r/r_functions.htm) is any chunk of organized code that is used to perform an operation. Source code is the underlying `R` or `c` or `c++` code that is used to create the function. To see the source code of a defined function, type the function's name without the `()`. For example, if we were curious about what the function `Reduce` does, we could run:

```{r, eval=F}
Reduce
```

Occasionally this will be less useful as the resulting code will be code that calls `c` code we can't see. Other times it will allow you to understand the function better.

#### Dataset

The following questions will use the dataset found in Scholar:

`/class/datamine/data/amazon/amazon_fine_food_reviews.csv`

A public sample of the data can be found here: [amazon_fine_food_reviews.csv](https://www.datadepot.rcac.purdue.edu/datamine/amazon/amazon_fine_food_reviews.csv)

Answers to questions should all be answered using the full dataset located on Scholar. You may use the public samples of data to experiment with your solutions prior to running them using the full dataset.

#### Questions

##### 1. What is the `Id` of the most helpful review if we consider the review with highest `HelpfulnessNumerator` to be an indicator of helpfulness (higher is more helpful)?

**Relevant topics:** *[cut](https://thedatamine.github.io/the-examples-book/unix.html#cut), [sort](https://thedatamine.github.io/the-examples-book/unix.html#sort), [head](https://thedatamine.github.io/the-examples-book/unix.html#head), [piping](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection)*

```{block, type="bbox"}
**Item(s) to submit:**

- Line of UNIX commands used to solve the problem.
- The `Id` of the most helpful review.
```

##### 2. What proportion of all `Summary`s are unique? Use two lines of UNIX commands to find the answer.

**Relevant topics:** *[cut](https://thedatamine.github.io/the-examples-book/unix.html#cut), [uniq](https://thedatamine.github.io/the-examples-book/unix.html#uniq), [sort](https://thedatamine.github.io/the-examples-book/unix.html#sort), [wc](https://thedatamine.github.io/the-examples-book/unix.html#wc), [piping](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection)*

```{block, type="bbox"}
**Item(s) to submit:**

- Two lines of UNIX commands used to solve the problem.
- The ratio of unique `Summary`'s.
```

##### 3. Use a simple UNIX command to create a frequency table of `Score`.

**Relevant topics:** *[cut](https://thedatamine.github.io/the-examples-book/unix.html#cut), [uniq](https://thedatamine.github.io/the-examples-book/unix.html#uniq), [sort](https://thedatamine.github.io/the-examples-book/unix.html#sort), [piping](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection)*

```{block, type="bbox"}
**Item(s) to submit:**

- The line of UNIX commands used to solve the problem.
- The frequency table.
```

##### 4. Who is the user with the highest number of reviews? There are two columns you could use to answer this question, but which column do you think would be most appropriate and why?

**Hint:** *You may need to pipe the output to `sort` multiple times.*

**Hint:** *To create the frequency table, read through the `man` pages for `uniq`. Man pages are the "manual" pages for UNIX commands. You can read through the man pages for uniq by running the following:*

```{bash, eval=F}
man uniq
```

**Relevant topics:** *[cut](https://thedatamine.github.io/the-examples-book/unix.html#cut), [uniq](https://thedatamine.github.io/the-examples-book/unix.html#uniq), [sort](https://thedatamine.github.io/the-examples-book/unix.html#sort), [head](https://thedatamine.github.io/the-examples-book/unix.html#head), [piping](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection), [man](https://thedatamine.github.io/the-examples-book/unix.html#man)*

```{block, type="bbox"}
**Item(s) to submit:**

- The line of UNIX commands used to solve the problem.
- The frequency table.
```

##### 5. Anecdotally, there seems to be a tendency to leave reviews when we feel strongly (either positive or negative) about a product. For the user with the highest number of reviews, would you say that they follow this pattern of extremes? Let's consider 5 star reviews to be strongly positive and 1 star reviews to be strongly negative. Let's consider anything in between neither strongly positive nor negative.

**Hint:** *You may find the solution to problem (3) useful.*

**Relevant topics:** *[cut](https://thedatamine.github.io/the-examples-book/unix.html#cut), [uniq](https://thedatamine.github.io/the-examples-book/unix.html#uniq), [sort](https://thedatamine.github.io/the-examples-book/unix.html#sort), [grep](https://thedatamine.github.io/the-examples-book/unix.html#grep), [piping](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection)*

```{block, type="bbox"}
**Item(s) to submit:**

- The line of UNIX commands used to solve the problem.
```

##### 6. We want to compare the most helpful review with a `Score` of 5 with the most helpful review with a `Score` of 1. Use UNIX commands to calculate these values. Write down the `ProductId` of both reviews. In the case of a tie, write down all `ProductId`'s to get full credit. In this case we are considering the most helpful review to be the review with the highest `HelpfulnessNumerator`.

**Hint:** *You can use multiple lines to solve this problem.*

**Relevant topics:** *[sort](https://thedatamine.github.io/the-examples-book/unix.html#sort), [head](https://thedatamine.github.io/the-examples-book/unix.html#head), [piping](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection)*

```{block, type="bbox"}
**Item(s) to submit:**

- The lines of UNIX commands used to solve the problem.
- `ProductId`'s of both requested reviews.
```

##### 7. Using the `ProductId`'s from the previous question, create a new dataset called `reviews.csv` which contains the `ProductId`'s and `Score` of all reviews with the corresponding `ProductId`'s.  

**Relevant topics:** *[cut](https://thedatamine.github.io/the-examples-book/unix.html#cut), [grep](https://thedatamine.github.io/the-examples-book/unix.html#head), [redirection](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection)*

```{block, type="bbox"}
**Item(s) to submit:**

- The line of UNIX commands used to solve the problem.
```

##### 8. If we didn't use `cut` prior to searching for the `ProductId`'s in (7), we would get unwanted results. Modify the solution to (7) and explore. What is happening?

**Relevant topics:** *[cat](https://thedatamine.github.io/the-examples-book/unix.html#cat), [grep](https://thedatamine.github.io/the-examples-book/unix.html#head), [redirection](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection)*

```{block, type="bbox"}
**Item(s) to submit:**

- The line of UNIX commands used to solve the problem.
- 1-2 sentences explaining why we need to use `cut` first.
- 1-2 sentences explaining whether or not you think people found the review helpful because the produce is overrated, underrated, or correctly reviewed, and why.
```

##### 9. Use R to load up `reviews.csv` into a new data.frame called `dat`. Create a histogram for each products' `Score`. Compare the most helpful review `Score` with the `Score`'s given in the histogram. Based on this comparison, decide (anecdotally) whether you think people found the review helpful because the product is overrated, underrated, or correctly reviewed by the masses.

**Relevant topics:** *[read.csv](file:///Users/kamstut/Dropbox/work/datamine/the-examples-book/docs/r.html#r-reading-and-writing-data), [hist](file:///Users/kamstut/Dropbox/work/datamine/the-examples-book/docs/r.html#r-plotting)*

```{block, type="bbox"}
**Item(s) to submit:**

- R code used to create the histograms.
- 3 histograms, 1 for each `ProductId`.
```

---


### Project 6

---

**Motivation:** A bash script is a powerful tool to perform repeated tasks. RCAC uses bash scripts to automate a variety of tasks. In fact, we use bash scripts on Scholar to do things like link Python kernels to your account, fix potential isues with Firefox, etc. `awk` is a programming language designed for text processing. The combination of these tools can be really powerful and useful for a variety of quick tasks.

**Context:** This is the first part in a series of projects that are designed to exercise skills around UNIX utilities, with a focus on writing bash scripts and `awk`. You will get the opportunity to manipulate data without leaving the terminal. At first it may seem overwhelming, however, with just a little practice you will be able to accomplish data wrangling tasks really efficiently. 

**Scope:** awk, UNIX utilities, bash scripts

**Learning objectives:**

```{block, type="bbox"}
- Use `awk` to process and manipulate textual data.
- Use piping and redirection within the terminal to pass around data between utilities.
- Use output created from the terminal to create a plot using R.
```

#### Dataset: 

The following questions will use the dataset found in Scholar:
`/class/datamine/data/flights/subset/YYYY.csv` 

An example of the data for the year 1987 can be found [here](https://www.datadepot.rcac.purdue.edu/datamine/flights/subset/1987.csv).

#### Questions

##### 1. In previous projects we learned how to get a single column of data from a csv file. Write 1 line of UNIX commands to print the 17th column, the `Origin`, from `1987.csv`. Write another line, this time using `awk` to do the same thing. Which one do you prefer, and why?

**Relevant topics:** [cut](#cut), [awk](#awk)

```{block, type="bbox"}
**Item(s) to submit:**

- One line of UNIX commands to solve the problem _without_ using `awk`.
- One line of UNIX commands to solve the problem using `awk`.
- 1-2 sentences describing which method you prefer and why.
```

##### 2. Write a bash script that accepts a year (1987, 1988, etc.) and a column *n* and returns the *nth* column of the associated year of data.

**Relevant topics:** [awk](#awk), [bash scripts](#writing-scripts)

```{block, type="bbox"}
**Item(s) to submit:**

- The content of your bash script (starting with "#!/bin/bash") in a code chunk.
```

##### 3. How many flights came into Indianapolis (IND) in 2008? First solve this problem without using `awk`, then solve this problem using *only* `awk`.

**Relevant topics:** [cut](#cut), [grep](#grep), [wc](#wc), [awk](#awk), [piping](#piping-and-redirection)

```{block, type="bbox"}
**Item(s) to submit:**

- One line of UNIX commands to solve the problem *without* using `awk`.
- One line of  UNIX commands to solve the problem using `awk`. 
- The number of flights that came into Indianapolis (IND) in 2008.
```

##### 4. Do you expect the number of unique origins and destinations to be the same? Find out using any command line tool you'd like. Are they indeed the same? How many unique values do we have per category (`Origin`, `Dest`)?

**Relevant topics:** [cut](#cut), [sort](#sort), [uniq](#uniq), [wc](#wc), [awk](#awk)

```{block, type="bbox"}
**Item(s) to submit:**

- 1-2 sentences explaining whether or not you expect the number of unique origins and destinations to be the same.
- The UNIX command(s) used to figure out if the number of unique origins and destinations are the same. 
- The number of unique values per category (`Origin`, `Dest`).
```

##### 5. In (4) we found that there are not the same number of unique `Origin`'s as `Dest`'s. Find the IATA airport code for all `Origin`'s that dont appear in a `Dest` and all `Dest`'s that don't appear in an `Origin`.

**Hint:** https://www.tutorialspoint.com/unix_commands/comm.htm

**Relevant topics:** [comm](#unix), [cut](#cut), [sort](#sort), [uniq](#uniq), [redirection](#piping-and-redirection)

```{block, type="bbox"}
**Item(s) to submit:**

- The line(s) of UNIX command(s) used to answer the question.
- The list of `Origin`s that don't appear in `Dest`.
- The list of `Dest`s that don't appear in `Origin`.
```

##### 6. What was the average number of flights in 2008 per unique `Origin` with the `Dest` of "IND"? How does "PHX" (as a unique `Origin`) compare to the average?

**Hint:** You manually do the average calculation by dividing the result from (3) by the number of unique `Origin`'s that have a `Dest` of "IND".

**Relevant topics:** [awk](#awk), [sort](#sort), [grep](#grep), [wc](#wc)

```{block, type="bbox"}
**Item(s) to submit:**

- The average number of flights in 2008 per unique `Origin` with the `Dest` of "IND".
- 1-2 sentences explaining how "PHX" compares (as a unique `Origin`) to the average?
```

##### 7. Write a bash script that takes a year and IATA airport code and returns the year, and the total number of flights to and from the given airport. Example rows may look like:

```{txt, eval=F}
1987, 12345
1988, 44
```

Run the script with inputs: `1991` and `ORD`. Include the output in your submission.

**Relevant topics:** [bash scripts](#writing-scripts), [cut](#cut), [piping](#piping-and-redirection), [grep](#grep), [wc](#wc)

```{block, type="bbox"}
**Item(s) to submit:**

- The content of your bash script (starting with "#!/bin/bash") in a code chunk.
- The output of the script given `1991` and `ORD` as inputs.
```

##### 8. Pick your favorite airport and get its IATA airport code. Write a bash script that, given the first year, last year, and airport code, runs the bash script from (7) for all years in the provided range for your given airport, or loops through all of the files for the given airport, appending all of the data to a new file called `my_airport.csv`.

**Relevant topics:** [bash scripts](#writing-scripts), [cut](#cut), [grep](#grep), [wc](#wc), for loops, echo, [redirection](#piping-and-redirection)

```{block, type="bbox"}
**Item(s) to submit:**

- The content of your bash script (starting with "#!/bin/bash") in a code chunk.
```

##### 9. In R, load `my_airport.csv` and create a line plot showing the year-by-year change. Label your x-axis "Year", your y-axis "Num Flights", and your title the name of the IATA airport code. Write 1-2 sentences with your observations.

**Relevant topics:** [read.csv](#r-reading-and-writing-data), lines

```{block, type="bbox"}
**Item(s) to submit:**

- Line chart showing year-by-year change in flights into and out of the chosen airport.
- R code used to create the chart.
- 1-2 sentences with your observations.
```

---

### Project 7

**Motivation:** A bash script is a powerful tool to perform repeated tasks. RCAC uses bash scripts to automate a variety of tasks. In fact, we use bash scripts on Scholar to do things like link Python kernels to your account, fix potential isues with Firefox, etc. `awk` is a programming language designed for text processing. The combination of these tools can be really powerful and useful for a variety of quick tasks.

**Context:** This is the first part in a series of projects that are designed to exercise skills around UNIX utilities, with a focus on writing bash scripts and `awk`. You will get the opportunity to manipulate data without leaving the terminal. At first it may seem overwhelming, however, with just a little practice you will be able to accomplish data wrangling tasks really efficiently. 

**Scope:** awk, UNIX utilities, bash scripts

**Learning objectives:**

```{block, type="bbox"}
- Use `awk` to process and manipulate textual data.
- Use piping and redirection within the terminal to pass around data between utilities.
```

#### Dataset: 

The following questions will use the dataset found in Scholar:

`/class/datamine/data/flights/subset/YYYY.csv` 

An example of the data for the year 1987 can be found [here](https://www.datadepot.rcac.purdue.edu/datamine/flights/subset/1987.csv).

Sometimes if you are about to dig into a dataset, it is good to quickly do some sanity checks early on to make sure the data is what you expect it to be. 

#### Questions

##### 1. Write a line of code that prints a list of the unique values in the `DayOfWeek` column. Write a line of code that prints a list of the unique values in the `DayOfMonth` column. Write a line of code that prints a list of the unique values in the `Month` column. Use the `1987.csv` dataset. Are the results what you expected?

**Relevant topics:** [cut](#cut), [sort](#sort)

```{block, type="bbox"}
**Item(s) to submit:**

- 3 lines of code used to get a list of unique values for the chosen columns.
- 1-2 sentences explaining whether or not the results are what you expected.
```

##### 2. Our files should have 29 columns. Write a line of code that prints any lines in a file that do *not* have 29 columns. Test it on `1987.csv`, were there any rows without 29 columns?

**Relevant topics:** [awk](#awk)

```{block, type="bbox"}
**Item(s) to submit:**

- Line of code used to solve the problem.
- 1-2 sentences explaining whether or not there were any rows without 29 columns.
```

##### 3. Write a bash script that, given a "begin" year and "end" year, cycles through the associated files and prints any lines that do *not* have 29 columns.

**Relevant topics:** [awk](#awk), [bash scripts](#writing-scripts)

```{block, type="bbox"}
**Item(s) to submit:**

- The content of your bash script (starting with "#!/bin/bash") in a code chunk.
- The results of running your bash scripts from year 1987 to 2008.
```

##### 4. `awk` is a really good tool to quickly get some data and manipulate it a little bit. For example, let's see the number of kilometers and miles traveled in 1990. To convert from miles to kilometers, simply multiply by 1.609344. 

Example output:

```txt
Miles: 12345
Kilometers: 19867.35168
```

**Relevant topics:** [awk](#awk), [piping](#piping-and-redirection)

```{block, type="bbox"}
**Item(s) to submit:**

- The code used to solve the problem. 
- The results of running the code.
```

##### 5. Use `awk` to calculate the number of `DepDelay` minutes by `DayOfWeek`. Use `2007.csv`.

Example output:

```txt
DayOfWeek:  0
1:  1234567
2:  1234567
3:  1234567
4:  1234567
5:  1234567
6:  1234567
7:  1234567
```

Note: 1 is Monday.

**Relevant topics:** [awk](#awk), [sort](#sort), [piping](#piping-and-redirection)

```{block, type="bbox"}
**Item(s) to submit:**

- The code used to solve the problem.
- The output from running the code.
```

##### 6. It wouldn't be fair to compare the total `DepDelay` minutes by `DayOfWeek` as the number of flights may vary. One way to take this into account is to instead calculate an average. Modify (5) to calculate the average number of `DepDelay` minutes by the number of flights per `DayOfWeek`. Use `2007.csv`.

Example output:

```txt
DayOfWeek:  0
1:  1.234567
2:  1.234567
3:  1.234567
4:  1.234567
5:  1.234567
6:  1.234567
7:  1.234567
```

**Relevant topics:** [awk](#awk), [sort](#sort), [piping](#piping-and-redirection)

```{block, type="bbox"}
**Item(s) to submit:**

- The code used to solve the problem.
- The output from running the code.
```

##### 7. As a quick follow-up, _slightly_ modify (6) to perform the same calculation for `ArrDelay`. Do the `ArrDelay`s and `DepDelay`s appear to have the highest delays on the same day? Use `2007.csv`.

Example output:

```txt
DayOfWeek:  0
1:  1.234567
2:  1.234567
3:  1.234567
4:  1.234567
5:  1.234567
6:  1.234567
7:  1.234567
```

**Relevant topics:** [awk](#awk), [sort](#sort), [piping](#piping-and-redirection)

```{block, type="bbox"}
**Item(s) to submit:**

- The code used to solve the problem.
- The output from running the code.
- 1-2 sentences explaining whether or not the `ArrDelay`s and `DepDelay`s appear to have the highest delays on the same day.
```

##### 8. Anyone who has flown knows how frustrating it can be waiting for takeoff, or deboarding the aircraft. These roughly translate to `TaxiOut` and `TaxiIn` respectively. If you were to fly into or out of IND what is your expected total taxi time? Use `2007.csv`.

Note: Taxi times are in minutes.

**Relevant topics:** [awk](#awk), [grep](#grep)

```{block, type="bbox"}
**Item(s) to submit:**

- The code used to solve the problem.
- The output from running the code.
```

##### 9.  What are the IATA airport codes of the 5 airports with the greatest total taxi time for 2007? Show the total taxi time for each.

Example output:

```txt
DayOfWeek:  0
IND: 1234567
IND: 1234567
IND: 1234567
IND: 1234567
IND: 1234567
```

**Relevant topics:** [awk](#awk), [head](#head), [sort](#sort)

```{block, type="bbox"}
**Item(s) to submit:**

- The code used to solve the problem.
- The output from running the code.
```

---

### Project 8

--- 

**Motivation:** A bash script is a powerful tool to perform repeated tasks. RCAC uses bash scripts to automate a variety of tasks. In fact, we use bash scripts on Scholar to do things like link Python kernels to your account, fix potential isues with Firefox, etc. `awk` is a programming language designed for text processing. The combination of these tools can be really powerful and useful for a variety of quick tasks.

**Context:** This is the first part in a series of projects that are designed to exercise skills around UNIX utilities, with a focus on writing bash scripts and `awk`. You will get the opportunity to manipulate data without leaving the terminal. At first it may seem overwhelming, however, with just a little practice you will be able to accomplish data wrangling tasks really efficiently. 

**Scope:** awk, UNIX utilities, bash scripts

**Learning objectives:**

```{block, type="bbox"}
- Use `awk` to process and manipulate textual data.
- Use piping and redirection within the terminal to pass around data between utilities.
```

#### Dataset: 

The following questions will use the dataset found in Scholar:

`/class/datamine/data/flights/subset/YYYY.csv` 

An example of the data for the year 1987 can be found [here](https://www.datadepot.rcac.purdue.edu/datamine/flights/subset/1987.csv).

Let's say we have a theory that there are more flights on the weekend days (Friday, Saturday, Sunday) than the rest of the days, on average. We can use awk to quickly check it out and see if maybe this looks like something that is true!

##### 1. Write a line of `awk` code that, prints the number of flights on the weekend days, followed by the number of flights on the weekdays for the flights during 2008.

**Relevant topics:** [awk](#awk)

```{block, type="bbox"}
**Item(s) to submit:**

- Line of `awk` code that solves the problem.
- The result: the number of flights on the weekend days, followed by the number of flights on the weekdays for the flights during 2008.
```

##### 2. Note that in (1), we are comparing 3 days to 4! Write a line of `awk` code that, prints the average number of flights on a weekend day, followed by the average number of flights on the weekdays. Continue to use data for 2008.

**Relevant topics:** [awk](#awk)

```{block, type="bbox"}
**Item(s) to submit:**

- Line of `awk` code that solves the problem.
- The result: the average number of flights on the weekend days, followed by the average number of flights on the weekdays for the flights during 2008.
```

We want to look to see if there may be some truth to the whole "snow bird" concept where people will travel to warmer states like Florida and Arizona during the Winter. Let's use the tools we've learned to explore this a little bit. 

##### 3. Take a look at `airports.csv`. In particular run the following:

```{bash, eval=F}
head airports.csv
```

Notice how all of the non-numeric text is surrounded by quotes. The surrounding quotes would need to be escaped for any comparison within `awk`. This is messy and we would prefer to create a new file called `new_airports.csv` without any quotes. Write a line of code to do this. 

**Hint:** You could use `gsub` within `awk` to replace '"' with ''.

**Hint:** If you leave out the column number argument to `gsub` it will apply the substitution to every field in every column.

**Relevant topics:** [awk](#awk), [redirection](#piping-and-redirection)

```{block, type="bbox"}
**Item(s) to submit:**

- Line of `awk` code used to create the new dataset.
```

##### 4. Write a line of commands that create a new dataset called `az_fl_airports.txt` that contains a list of airport codes for all airports from both Arizona (AZ) and Florida (FL). Use the file we created in (3),`new_airports.csv`.

**Relevant topics:** [awk](#awk)

```{block, type="bbox"}
**Item(s) to submit:**

- The line of UNIX commands to create an array called `airports`.
```

##### 5. Wow! In (4) we discovered a lot of airports! How many airports are there? Did you expect this? Use a line of bash code to answer this question.

**Relevant topics:** [echo](#echo), [wc](#wc), [piping](#piping-and-redirection)

```{block, type="bbox"}
**Item(s) to submit:**

- Line of UNIX commands used to solve the problem.
- The number of airports.
- 1-2 sentences explaining whether you expected this result and why or why not.
```

##### 6. Create a new dataset that contains all of the data for flights into or out of Florida and Arizona using 2008.csv, use the newly created dataset, `az_fl_airports.txt` in (4) to do so.

**Hint:** https://unix.stackexchange.com/questions/293684/basic-grep-awk-help-extracting-all-lines-containing-a-list-of-terms-from-one-f

**Relevant topics:** [grep](#grep)

```{block, type="bbox"}
**Item(s) to submit:**

- Line of UNIX commands used to solve the problem.
```

##### 7. Now that you have code to complete (6), write a bash script that accepts the start year, end year, and filename containing airport codes (`az_fl_airports.txt`), and outputs the data for flights into or out of any of the airports listed in the provided filename containing airport codes using _all_ of the years of data in the provided range. Run the bash script to create a new file called `az_fl_flights.csv`.

**Relevant topics:** [bash scripts](#writing-scripts), [grep](#grep), for loop, [redirection](#piping-and-redirection)

```{block, type="bbox"}
**Item(s) to submit:**

- The content of your bash script (starting with "#!/bin/bash") in a code chunk.
- The line of UNIX code you used to execute the script and create the new dataset.
```

##### 8. Use the newly created `az_fl_flights.csv` dataset to calculate the total number of flights into and out of both states by month, and by year, for a total of 3 columns (year, month, flights). Export this information to a new file called `snowbirds.csv`.

**Relevant topics:** [awk](#awk), [redirection](#piping-and-redirection)

```{block, type="bbox"}
**Item(s) to submit:**

- The line of `awk` code used to create the new dataset, `snowbirds.csv`.
```

##### 9. Load up your newly created dataset and use either R or Python (or some other tool) to create a graphic that illustrates whether or not we believe the "snowbird effect" effects flights. Include a description of your graph, as well as your (anecdotal) conclusion.

```{block, type="bbox"}
**Item(s) to submit:**

- Code used to create the visualization in a code chunk.
- The generated plot as either a png or jpg/jpeg.
- 1-2 sentences describing your plot and your conclusion.
```

---


