= STAT-LLC 2018 bash and awk Exercises

== Project 1

Question 1.

Use the airline data stored in this directory:

`/depot/statclass/data/dataexpo2009`

In the year 2005, find:

a.  the number of flights that occurred, on every day of the year, and

b.  find the day of the year on which the most flights occur.

Soution:

We switch to the directory for the airline data

`cd /depot/statclass/data/dataexpo2009`

a. The number of flights that occurred, on every day of the year, can be obtained by extracting the 1st, 2nd, and 3rd fields, sorting the data, and then summarizing the data using the uniq command with the `-c` flag

`sort 2005.csv | cut -d, -f1-3 | sort | uniq -c`

The first few lines of the output are:

[source,bash]
----
16477 2005,10,1
19885 2005,10,10
19515 2005,10,11
19701 2005,10,12
19883 2005,10,13
----

and the last few lines of the output are:

[source,bash]
----
20051 2005,9,6
19629 2005,9,7
19968 2005,9,8
19938 2005,9,9
    1 Year,Month,DayofMonth
----

b. The day of the year on which the most flights occur can be found by sorting the results above, in numerical order, using `sort -n` and then (if desired, although it is optional) we can extract the last line of the output using `tail -n1`

`sort 2005.csv | cut -d, -f1-3 | sort | uniq -c | sort -n | tail -n1`

and we conclude that the most flights occur on August 5:

`21041 2005,8,5`


Question 2.

Again considering the year 2005, did United or Delta have more flights?

Solution:

We can extract the 9th field, which is the carrier (i.e., the airline company) and then, in the same way as above, we can sort the data, and then we can summarize the data using `uniq -c`

This yields the number of flights for each carrier.

We can either read the number of United or Delta flights with our eyeballs, or we can use the grep command, searching for both the pattern UA and DL to isolate (only) the number of flights for United and Delta, respectively.

`sort 2005.csv | cut -d, -f9 | sort | uniq -c | grep "UA\|DL"`

The output is:

[source,bash]
----
658302 DL
485918 UA
----

so Delta has more flights than United in 2005.


Question 3.

Consider the June 2017 taxi cab data, which is located in this folder:

`/depot/statclass/data/taxi2018`

What is the distribution of the number of passengers in the taxi cab rides?  In other words, make a list of the number of rides that have 1 passenger; that have 2 passengers; etc.

Solution:

Now we change directories to consider the taxi cab data

`cd ../taxi2018`

The `..` in the previous command just indicates that we want to go up one level to `/depot/statclass/data` and then, from that point, we want to go into the taxi cab directory.  If this sounds complicated, then (instead) it is safe to use the longer version:

`cd /depot/statclass/data/taxi2018`

The number of passengers is given in the 4th column, `passenger_count`

We use a method that is similar to the one from the first three questions, we extract the 4th column, sort the data, and then summarizing the data using the uniq command with the -c flag

`sort yellow_tripdata_2017-06.csv | cut -d, -f4 | sort | uniq -c`

and the distribution of the number of passengers is:

[source,bash]
----
      1 
    548 0
6933189 1
1385066 2
 406162 3
 187979 4
 455753 5
 288220 6
     26 7
     30 8
     20 9
      1 passenger_count
----

Notice that we have some extraneous information, i.e., there is one blank line and also one line for the passenger_count (from the header)



Question 4.

Revisit question 1a, but using all of the data about all of the flights, from 1987 to 2008.  (Note: It is not necessary to run 22 separate commands for this purpose.)

Solution:

To revisit question 1a, we first change back to the airline directory using

`cd ../dataexpo2009`

or using

`cd /depot/statclass/data/dataexpo2009`

Then we perform the same operations as above, but working on the file `allyears.csv`

`sort allyears.csv | cut -d, -f1-3 | sort | uniq -c`

An alternative, we could work on the collection of all of the files whose name starts with a 1 or a 2 We do not just use `*.csv` because in this method, we do not want to work on the file `allnames.csv` in this method (that would double our answers)

`sort [1-2]*.csv | cut -d, -f1-3 | sort | uniq -c`

The first few lines of the output, with either method, are:

[source,bash]
----
14766 1987,10,1
13421 1987,10,10
14020 1987,10,11
14795 1987,10,12
14865 1987,10,13
----



Question 5.

a.  Give a distribution of the number of flights in the ASA Data Expo 2009 according to the day of the week.

b.  Which day of the week is the most popular for travel?

c.  Which day of the week is least popular for travel?

Solution:

a. To find the most popular day of the week for travel, we extract the 4th field, which contains the DayOfWeek, and we summarize it, in the same way that we did above. Either of these two methods will work:

`sort allyears.csv | cut -d, -f4 | sort | uniq -c | sort -n`

or we can compute:

`sort [1-2]*.csv | cut -d, -f4 | sort | uniq -c | sort -n`

We get the following distribution of the days of the week:

[source,bash]
----
15915382 6
17143178 7
18061938 2
18083800 4
18091338 5
18103222 3
18136111 1
       1 DayOfWeek
----

b. We conclude that Monday (day 1) is the most popular for travel,

c. and Saturday (day 6) is the least popular for travel.


Question 6.

a.  Create a text file call `INDtoORD.txt` that contains the data about every flight from Indianapolis (IND) to Chicago O'Hare (ORD).

b.  Zip this data into a compressed file called `INDtoORD.zip`

Solution:

a. We can build such a file and store it in our home directory (please note that the tilde ~ refers to the home directory) as follows:

`grep "IND,ORD" allyears.csv >~/INDtoORD.txt`

or, alternatively, like this:

`grep IND,ORD [1-2]*.csv >~/INDtoORD.txt`

The first method yields a file that starts as follows:

[source,bash]
----
1987,10,31,6,1720,1721,1712,1714,UA,334,NA,52,53,NA,-2,-1,IND,ORD,177,NA,NA,0,NA,0,NA,NA,NA,NA,NA
1987,10,1,4,816,816,920,909,UA,453,NA,64,53,NA,11,0,IND,ORD,177,NA,NA,0,NA,0,NA,NA,NA,NA,NA
1987,10,2,5,816,816,921,909,UA,453,NA,65,53,NA,12,0,IND,ORD,177,NA,NA,0,NA,0,NA,NA,NA,NA,NA
1987,10,3,6,833,816,932,909,UA,453,NA,59,53,NA,23,17,IND,ORD,177,NA,NA,0,NA,0,NA,NA,NA,NA,NA
1987,10,4,7,814,816,906,909,UA,453,NA,52,53,NA,-3,-2,IND,ORD,177,NA,NA,0,NA,0,NA,NA,NA,NA,NA
----

The second method yields a file that starts as follows: (the extra characters at the start of each line show the file where the pattern was found)

[source,bash]
----
1987.csv:1987,10,31,6,1720,1721,1712,1714,UA,334,NA,52,53,NA,-2,-1,IND,ORD,177,NA,NA,0,NA,0,NA,NA,NA,NA,NA
1987.csv:1987,10,1,4,816,816,920,909,UA,453,NA,64,53,NA,11,0,IND,ORD,177,NA,NA,0,NA,0,NA,NA,NA,NA,NA
1987.csv:1987,10,2,5,816,816,921,909,UA,453,NA,65,53,NA,12,0,IND,ORD,177,NA,NA,0,NA,0,NA,NA,NA,NA,NA
1987.csv:1987,10,3,6,833,816,932,909,UA,453,NA,59,53,NA,23,17,IND,ORD,177,NA,NA,0,NA,0,NA,NA,NA,NA,NA
1987.csv:1987,10,4,7,814,816,906,909,UA,453,NA,52,53,NA,-3,-2,IND,ORD,177,NA,NA,0,NA,0,NA,NA,NA,NA,NA
----

b. Now we zip the file (again the tilde ~ just refers to the fact that these files are both in the home directory)

`zip ~/INDtoORD.zip ~/INDtoORD.txt`


Question 7.

a.  Identify the 10 airports in the ASA Data Expo 2009 that are the busiest, according to the number of departures (i.e., according to serving as the origin airport for flights).

b.  Use the grep command (with multiple patterns) to store the complete data (all 29 parameters) about these 10 airports, into a file called `popularairportdata.txt`.

Solution:

a. We identify the airports by extracting the 17th field and then sorting and counting the lines, and then sorting the results, as we did several times in the previous problems.  The tail contains the 10 most popular airports.

`sort allyears.csv | cut -d, -f17 | sort | uniq -c | sort -n | tail`

[source,bash]
----
2733910 SFO
2754997 MSP
2884518 IAH
2979158 DTW
3319905 DEN
3491077 PHX
4089012 LAX
5710980 DFW
6100953 ATL
6597442 ORD
----

b. We can grep for any line that contains data about these 10 airports:

`grep "SFO\|MSP\|IAH\|DTW\|DEN\|PHX\|LAX\|DFW\|ATL\|ORD" allyears.csv >~/popularairportdata.txt`


Question 8.

How many distinct airports are represented in the ASA Data Expo?

Solution:

One method is to put the 17th and 18th fields in a file with two commands. Please note that we used a double right carrot so that the output gets appended to the file without deleting the file

[source,bash]
----
cat allyears.csv | cut -d, -f17 >>~/airportcodes.txt
cat allyears.csv | cut -d, -f18 >>~/airportcodes.txt
----

and then we could sort the file and find the number of unique airport codes.

The `wc` command counts the number of lines, words, and characters but here we use wc -l because we only need the number of lines (one line per airport)

`sort ~/airportcodes.txt | uniq | wc -l`

There are 354 airports altogether.

An alternative, one line method is to enable the cut command to print a newline after each field, so that we can print the 17th field and then a newline followed by the 18th field and then a newline. That way, we still get one airport per line.

`cat allyears.csv | cut -d, -f17-18 --output-delimiter=$'\n' | sort | uniq | wc -l`

Again we see that there are 354 airports altogether.



Question 9.

a.  Revisit question 3, but using all of the data about all of the taxi cab rides, from 2009 to 2017.  (Note: It is not necessary to run dozens of separate commands for this purpose.)

b.  Do you notice anything unusual about this data?

Solution:

a. We change directories to consider the taxi cab data

`cd ../taxi2018`

We extract the 4th field across all files now, using the similar method to the one that we used above. Since this operation takes a long time to run, we store the results in a file. We also use the `nohup` option, which needs an ampersand (the is the "&") at the end of the line, so that this process can run in the background while we are working on other things.

`nohup cat yellow*.csv | cut -d, -f4 | sort | uniq -c | sort -n >~/taxidistribution.txt &`

and the distribution of the number of passengers includes (among many others):

[source,bash]
----
      974 8
     1165 7
     1495 208
  3800950 0
 29462601 4
 32640245 6
 60751390 3
 92684661 5
205576933 2
971920078 1
----

b. Some of the taxi cab rides seem to have a very large number of passengers, but this is a result of some errors in the data set.  For instance, we see taxi cab rides here that have 208 passengers, which is impossible.



Question 10.

a.  Find the number of taxi cab rides per day in June 2017.  (Use the date when the cabs depart, in case the trip lasts past midnight.)  Hint:  You might need to use *two* cut commands, since you will need to extract the data about the day from the timestamp.  The exact time of departure is given, but the hours, minutes, and seconds are not needed for this question, and must be avoided.

b.  Same question, but use all of the data about all of the taxi cab rides, from 2009 to 2017.

Solution:

a. We first extract the 2nd field, which has the date and time of the departure of each trip:

`head yellow_tripdata_2017-06.csv | cut -d, -f2`

Then we need to run this through the cut command again, this time using a space as the delimiter: and (since this intermediate result had only two fields, namely, the date and the time), this time we extract the first field.

`head yellow_tripdata_2017-06.csv | cut -d, -f2 | cut -d' ' -f1`

and (changing head to cat, so that we examine the entire file) now we are prepared to use this strategy on the full month of taxi cab rides:

`cat yellow_tripdata_2017-06.csv | cut -d, -f2 | cut -d' ' -f1 | sort | uniq -c`

The first few lines of output are the following (notice that we had one blank line)

[source,bash]
----
     1 
344507 2017-06-01
347404 2017-06-02
341807 2017-06-03
294236 2017-06-04
----

and the last few lines of output are the following (notice that we have the header in the output too)

[source,bash]
----
321083 2017-06-27
316000 2017-06-28
313277 2017-06-29
302847 2017-06-30
     1 tpep_pickup_datetime
----

b. Now we run this code on all of the taxi cab rides from all of the years, and we again use the "nohup" option, again with an ampersand at the end of the line, so that this process can run in the background while we are working on other things. We store the results in a file:

`nohup cat yellow*.csv | cut -d, -f2 | cut -d' ' -f1 | sort | uniq -c | sort -n >~/taxicountsbyday.txt &`

As with lots of data, there are some strange properties.  For instance, here are the first several lines of the file:

`head -n30 ~/taxicountsbyday.txt`

[source,bash]
----
     1 2001-01-06
     1 2002-12-31
     1 2018-01-20
     1 2018-02-04
     1 2041-11-15
     1 2053-03-21
     2 2001-01-01
     2 2003-01-01
     2 2018-02-07
     2 2018-03-01
     2 2018-03-19
     3 2003-01-14
     3 2018-01-17
     3 2018-02-25
     4 2018-04-30
     4 2018-05-22
     5 2018-04-09
    12 
    12 Trip_Pickup_DateTime
    26 2018-01-01
    35 2008-12-31
    36 tpep_pickup_datetime
    46 pickup_datetime
    82 
 29028 2011-08-28
 72025 2010-12-27
 78133 2016-01-23
100325 2017-03-14
113808 2012-10-29
135500 2015-01-27
----

This is the end of the first project!


== Project 2

Question 1.

a.  What was the average arrival delay (in minutes) for flights in 2005?

b.  What was the average departure delay (in minutes) for flights in 2005?

cd. Now revise your solution to 1ab, to account for the delays (of both types) in the full set of data, across all years.

Solution:

`cd /depot/statclass/data/dataexpo2009`

a.

basic solution:

`cat 2005.csv | awk -F, '{arrdelay += $15; flightcount++} END{print arrdelay/flightcount}'`

advanced solution:

`cat 2005.csv | grep -v ArrDelay | awk -F, '{if ($15!="NA") {arrdelay += $15; flightcount++}} END{print arrdelay/flightcount}'`

basic solution: 7.03274; advanced solution: 7.18134

b.

basic solution:

`cat 2005.csv | awk -F, '{depdelay += $16; flightcount++} END{print depdelay/flightcount}'`

advanced solution:

`cat 2005.csv | grep -v DepDelay | awk -F, '{if ($16!="NA") {depdelay += $16; flightcount++}} END{print depdelay/flightcount}'`

basic solution: 8.51186; advanced solution: 8.67431
	
c.

basic solution:

`cat [1-2]*.csv | awk -F, '{arrdelay += $15; flightcount++} END{print arrdelay/flightcount}'`

advanced solution:

`cat [1-2]*.csv | grep -v ArrDelay | awk -F, '{if ($15!="NA") {arrdelay += $15; flightcount++}} END{print arrdelay/flightcount}'`

basic solution: 6.90229; advanced solution: 7.04996

d.

basic solution:

`cat [1-2]*.csv | awk -F, '{depdelay += $16; flightcount++} END{print depdelay/flightcount}'`

advanced solution:

`cat [1-2]*.csv | grep -v DepDelay | awk -F, '{if ($16!="NA") {depdelay += $16; flightcount++}} END{print depdelay/flightcount}'`

basic solution: 8.01844; advanced solution: 8.17071

Question 2.

Revise your solutions to 1abcd to only include flights that took place on the weekends.

Solution:

a.

basic solution:

`cat 2005.csv | awk -F, '{if (($4 == 6) || ($4 == 7)) {arrdelay += $15; flightcount++}} END{print arrdelay/flightcount}'`

advanced solution:

`cat 2005.csv | grep -v ArrDelay | awk -F, '{if ((($4 == 6) || ($4 == 7)) && ($15!="NA")) {arrdelay += $15; flightcount++}} END{print arrdelay/flightcount}'`

basic solution: 4.84079; advanced solution: 4.93905

b.

basic solution:

`cat 2005.csv | awk -F, '{if (($4 == 6) || ($4 == 7)) {depdelay += $16; flightcount++}} END{print depdelay/flightcount}'`

advanced solution:

`cat 2005.csv | grep -v DepDelay | awk -F, '{if ((($4 == 6) || ($4 == 7)) && ($16!="NA")) {depdelay += $16; flightcount++}} END{print depdelay/flightcount}'`

basic solution: 7.51425; advanced solution: 7.65198

c.

basic solution:

`cat [1-2]*.csv | awk -F, '{if (($4 == 6) || ($4 == 7)) {arrdelay += $15; flightcount++}} END{print arrdelay/flightcount}'`

advanced solution:

`cat [1-2]*.csv | grep -v ArrDelay | awk -F, '{if ((($4 == 6) || ($4 == 7)) && ($15!="NA")) {arrdelay += $15; flightcount++}} END{print arrdelay/flightcount}'`

basic solution: 5.30331; advanced solution: 5.4005

d.

basic solution:

`cat [1-2]*.csv | awk -F, '{if (($4 == 6) || ($4 == 7)) {depdelay += $16; flightcount++}} END{print depdelay/flightcount}'`

advanced solution:

`cat [1-2]*.csv | grep -v DepDelay | awk -F, '{if ((($4 == 6) || ($4 == 7)) && ($16!="NA")) {depdelay += $16; flightcount++}} END{print depdelay/flightcount}'`

basic solution: 7.55609; advanced solution: 7.677

Question 3.

a.   What is the average departure delay on flights from IND to ORD?

b.   Double-check your work, by analyzing the file created in question 6ab in project 1.

Solution:

a.

basic solution:

`cat [1-2]*.csv | awk -F, '{if (($17 == "IND") && ($18 == "ORD")) {depdelay += $16; flightcount++}} END{print depdelay/flightcount}'`

advanced solution:

`cat [1-2]*.csv | grep -v DepDelay | awk -F, '{if ((($17 == "IND") && ($18 == "ORD")) && ($16!="NA")) {depdelay += $16; flightcount++}} END{print depdelay/flightcount}'`

basic solution: 8.85475; advanced solution: 9.13213

b.

basic solution:

`cat ~/INDtoORD.txt | awk -F, '{depdelay += $16; flightcount++} END{print depdelay/flightcount}'`

advanced solution:

`cat ~/INDtoORD.txt | grep -v DepDelay | awk -F, '{if ($16!="NA") {depdelay += $16; flightcount++}} END{print depdelay/flightcount}'`

`cd /depot/statclass/data/taxi2018`



Question 4.

a.   What is the average distance of a taxi cab ride in New York City in June 2017?

b.   Now revise your solution to 4a, to account for the full set of data, across all years.

Hint:  On problems that will take a very long time to run, like 4b, you can use the following method:

`nohup  allofyourusualcommandstuffgoeshere  >~/myoutputfile.txt &`

The `nohup` causes the program to keep running, even if you log out.
The ampersand lets you keep typing in the meantime.
The file called `myoutputfile.txt` will be saved in your home directory.
(The tilde stands for your home directory.  You can choose another location if you prefer, of course.)
You get a job number when you start a command running like this.  For instance, you job number might be 13788.
You can stop that job running at any point during its execution by typing, for instance, kill 13788

Solution:

a.

basic solution:

`cat yellow_tripdata_2017-06.csv | awk -F, '{distance += $5; taxicount++} END{print distance/taxicount}'`

advanced solution:

`cat yellow_tripdata_2017-06.csv | grep -v "istance" | awk -F, '{if (NF >= 3) {distance += $5; taxicount++}} END{print distance/taxicount}'`

solution: 2.97862

b.

basic solution:

`nohup cat yellow*.csv | awk -F, '{distance += $5; taxicount++} END{print distance/taxicount}' >~/newnewresult4a.txt &`

advanced solution:

`nohup cat yellow*.csv | grep -v "istance" | awk -F, '{if (NF >= 3) {distance += $5; taxicount++}} END{print distance/taxicount}' >~/newnewresult4b.txt &`

solution: 5.12591



Question 5.

For each taxi cab ride, compute the percentage of the ride's fare that is dedicated to the tolls.  What is this percentage, on average?

Solution:

[source,bash]
----
for year in {2009..2014}; do
  for month in {01..12}; do
    nohup cat yellow_tripdata_${year}-${month}.csv | grep -v olls | awk -F, '{if((NF > 3)&&($18!=0)) {percentage += $17/$18; counter++}} END{print percentage/counter, counter}' >~/taxitolls${year}-month${month}result.txt &
  done
done

for year in {2015..2015}; do
  for month in {01..12}; do
    nohup cat yellow_tripdata_${year}-${month}.csv | grep -v olls | awk -F, '{if((NF > 3)&&($19!=0)) {percentage += $17/$19; counter++}} END{print percentage/counter, counter}' >~/taxitolls${year}-month${month}result.txt &
  done
done

for year in {2016..2016}; do
  for month in {01..06}; do
    nohup cat yellow_tripdata_${year}-${month}.csv | grep -v olls | awk -F, '{if((NF > 3)&&($19!=0)) {percentage += $17/$19; counter++}} END{print percentage/counter, counter}' >~/taxitolls${year}-month${month}result.txt &
  done
done

for year in {2016..2016}; do
  for month in {07..12}; do
    nohup cat yellow_tripdata_${year}-${month}.csv | grep -v olls | awk -F, '{if((NF > 3)&&($17!=0)) {percentage += $15/$17; counter++}} END{print percentage/counter, counter}' >~/taxitolls${year}-month${month}result.txt &
  done
done

for year in {2017..2017}; do
  for month in {01..12}; do
    nohup cat yellow_tripdata_${year}-${month}.csv | grep -v olls | awk -F, '{if((NF > 3)&&($17!=0)) {percentage += $15/$17; counter++}} END{print percentage/counter, counter}' >~/taxitolls${year}-month${month}result.txt &
  done
done
----

once all of those are done running, then tabulate the data

`cat ~/taxitolls20*.txt | awk '{total += $1*$2; counter += $2} END{print total/counter}'`

solution: 0.00542058



Question 6.

Consider customers who pay for their taxi cabs with credit card versus with cash.  Does this distinction affect the distance traveled?

Solution:

[source,bash]
----
for year in {2009..2015}; do
  for month in {01..12}; do
    nohup cat yellow_tripdata_${year}-${month}.csv | grep -v ayment | awk -F, '{if(NF > 3) {totaldistance[$12] += $5; counter[$12]++;}} END{for (key in totaldistance) {print key, totaldistance[key], counter[key];}}' >~/taxipaymenttypes${year}-month${month}result.txt &
  done
done

for year in {2016..2016}; do
  for month in {01..06}; do
    nohup cat yellow_tripdata_${year}-${month}.csv | grep -v ayment | awk -F, '{if(NF > 3) {totaldistance[$12] += $5; counter[$12]++;}} END{for (key in totaldistance) {print key, totaldistance[key], counter[key];}}' >~/taxipaymenttypes${year}-month${month}result.txt &
  done
done

for year in {2016..2016}; do
  for month in {07..12}; do
    nohup cat yellow_tripdata_${year}-${month}.csv | grep -v ayment | awk -F, '{if(NF > 3) {totaldistance[$10] += $5; counter[$10]++;}} END{for (key in totaldistance) {print key, totaldistance[key], counter[key];}}' >~/taxipaymenttypes${year}-month${month}result.txt &
  done
done

for year in {2017..2017}; do
  for month in {01..12}; do
    nohup cat yellow_tripdata_${year}-${month}.csv | grep -v ayment | awk -F, '{if(NF > 3) {totaldistance[$10] += $5; counter[$10]++;}} END{for (key in totaldistance) {print key, totaldistance[key], counter[key];}}' >~/taxipaymenttypes${year}-month${month}result.txt &
  done
done

cat ~/taxipaymenttypes*.txt | awk '{if(!(($1 > 40)&&($1 < 42))) {print $0}}' | awk '{totaldistance[$1] += $2; totalcount[$1] += $3;} END{for (key in totaldistance) {print key, totaldistance[key], totalcount[key], totaldistance[key]/totalcount[key];}}'
----


Question 7.

a.  Use the method from the end of the notes, to add up the total number of miles flow by each airline, in 2005.

b.  Now revise your solution to 7a, to account for the full set of data, across all years.

Solution:

a.

`cd /depot/statclass/data/dataexpo2009`

`cat 2005.csv | grep -v UniqueCarrier | awk -F, '{distance[$9] += $19} END{for (key in distance) {print key, distance[key]}}'`

[source,bash]
----
AA 722852274
DL 564268170
XE 213291464
MQ 211059565
OO 195573943
CO 334136379
B6 150758132
FL 127526045
AS 138031164
TZ 47556475
HA 28642799
UA 532116122
OH 170772547
HP 200373825
NW 365044151
WN 628492880
F9 48562429
DH 60671620
EV 139250724
US 288955635
----

b.

`cat [1-2]*.csv | grep -v UniqueCarrier | awk -F, '{distance[$9] += $19} END{for (key in distance) {print key, distance[key]}}'`

[source,bash]
----
AA 14237240059
XE 1261704518
DL 11782682821
OO 1199143412
MQ 1446828218
PA (1) 213910356
TW 2733374003
B6 970096179
FL 843208347
AQ 52022302
CO 7290881290
ML (1) 47795815
EA 557435834
TZ 239451257
AS 2138434915
YV 339860468
HA 161922365
UA 12185717876
PS 30274790
OH 687290174
9E 235073027
NW 7301968497
HP 2735172637
WN 8085268722
F9 299595575
DH 259805885
PI 331802193
EV 764868753
US 8109732855
----


Question 8.

Repeat question 7ab but using the tail number (which is unique to each airplane) instead of the airline.

Solution:

a. Notice that we choose to print the distances and then the tailnums and we sort by the distances, and we are only printing the tail

`cat 2005.csv | grep -v UniqueCarrier | awk -F, '{distance[$11] += $19} END{for (key in distance) {print distance[key], key}}' | sort -n | tail`

[source,bash]
----
2034981 N211UA
2036892 N588JB
2039066 N590JB
2045220 N589JB
2045625 N593JB
2050927 N213UA
2060375 N598JB
2069280 N550JB
7597848 000000
37522198 0
----

b.

`cat [1-2]*.csv | grep -v UniqueCarrier | awk -F, '{distance[$11] += $19} END{for (key in distance) {print distance[key], key}}' | sort -n | tail`

[source,bash]
----
23882022 N550UA
23886947 N552UA
23893505 N543UA
24073793 N551UA
48624558 000000
81199937 
119055508 ï¿½NKNO
184998252 0
387812613 UNKNOW
23723559710 NA
----


Question 9.

Revisit question 4, breaking the results down according to the number of passengers.  Here is a basic outline of how to do this:

a.  Use the method from the end of the notes, to add up the total distance across all taxi rides, according to the number of passengers.

b.  Now augment the previous awk program to also include the total number of taxi rides, according to the number of passengers.

c.  Now add another feature:  At the end of the awk program, divide the total distance across all taxi rides (according to the number of passengers) by the corresponding total number of taxi rides (again, according to that same number of passengers).  With this method, at the end of the awk program, you can print the average distance per taxi ride, according to the number of passengers.

Solution:

`cd /depot/statclass/data/taxi2018`

abc (June 2017 only).

basic solution:

`cat yellow_tripdata_2017-06.csv | awk -F, '{distance[$4] += $5; taxicount[$4]++} END{ for (key in distance) {print key, distance[key]/taxicount[key]}}' | sort -n`

[source,bash]
----
 0
0 0.417445
passenger_count 0
1 2.92293
2 3.16181
3 3.09691
4 3.19115
5 3.03522
6 3.04735
7 3.54154
8 5.56933
9 5.4615
----

advanced solution:

`cat yellow_tripdata_2017-06.csv | grep -v "istance" | awk -F, '{if (NF >= 3) {distance[$4] += $5; taxicount[$4]++}} END{ for (key in distance) {print key, distance[key]/taxicount[key]}}' | sort -n`

[source,bash]
----
0 0.417445
1 2.92293
2 3.16181
3 3.09691
4 3.19115
5 3.03522
6 3.04735
7 3.54154
8 5.56933
9 5.4615
----

abc (all years).

basic solution:

`nohup cat yellow*.csv | awk -F, '{distance[$4] += $5; taxicount[$4]++} END{ for (key in distance) {print key, distance[key]/taxicount[key]}}' | sort -n >~/newnewresult9a.txt &`

[source,bash]
----
 0
0 2.30545
 passenger_count 0
passenger_count 0
Passenger_Count 0
1 5.52209
2 4.91924
3 4.88274
4 4.25553
5 2.74503
6 2.9605
7 3.30694
8 4.75099
9 5.90511
10 0.318235
13 12.89
15 2.21
17 9.18
19 0.69
25 0.87
33 1.615
34 3.57
36 20.16
37 2.16
38 1.45
47 2.56
49 0
51 2.65
53 1.86
58 5.815
61 8.78
65 7.51333
66 4.5
69 1.28
70 3.06
84 13.98
91 9.44
97 1.87
113 0
125 3.83
129 1.59
133 3.05
134 20.92
137 17.64
141 3.81
155 16.53
158 1.57
160 1.48
163 3.03
164 22.98
165 1.44
169 14.76
177 1.34
192 1.07
193 1.74
208 0.0582838
211 0.97
213 0
223 1.16
225 4.83
229 3.27
232 722862
247 3.31
249 1.69
250 3.64333
254 1.02
255 2.632
----

advanced solution:

`nohup cat yellow*.csv | grep -v "istance" | awk -F, '{if (NF >= 3) {distance[$4] += $5; taxicount[$4]++}} END{ for (key in distance) {print key, distance[key]/taxicount[key]}}' | sort -n >~/newnewresult9b.txt &`

[source,bash]
----
0 2.30545
1 5.52209
2 4.91924
3 4.88274
4 4.25553
5 2.74503
6 2.9605
7 3.30694
8 4.75099
9 5.90511
10 0.318235
13 12.89
15 2.21
17 9.18
19 0.69
25 0.87
33 1.615
34 3.57
36 20.16
37 2.16
38 1.45
47 2.56
49 0
51 2.65
53 1.86
58 5.815
61 8.78
65 7.51333
66 4.5
69 1.28
70 3.06
84 13.98
91 9.44
97 1.87
113 0
125 3.83
129 1.59
133 3.05
134 20.92
137 17.64
141 3.81
155 16.53
158 1.57
160 1.48
163 3.03
164 22.98
165 1.44
169 14.76
177 1.34
192 1.07
193 1.74
208 0.0582838
211 0.97
213 0
223 1.16
225 4.83
229 3.27
232 722862
247 3.31
249 1.69
250 3.64333
254 1.02
255 2.632
----




Question 10.

a. Find the number of taxi cab rides on each day in June 2017.

Hint:  You can use two delimiters like this:

`awk -F[,\ ]`

(the backslash is before the space to ensure that the space is detected)

b.  Does your answer to 10a agree with your answer to 10a from the previous problem set?

Solution:

10.

`cat yellow_tripdata_2017-06.csv | awk -F[,\ ] '{print $2}' | sort -n | uniq -c`

[source,bash]
----
      1 
      1 tpep_pickup_datetime
 344507 2017-06-01
 347404 2017-06-02
 341807 2017-06-03
 294236 2017-06-04
 304042 2017-06-05
 341499 2017-06-06
 339808 2017-06-07
 353452 2017-06-08
 342240 2017-06-09
 337959 2017-06-10
 283088 2017-06-11
 311495 2017-06-12
 333931 2017-06-13
 349305 2017-06-14
 347838 2017-06-15
 341823 2017-06-16
 318478 2017-06-17
 277743 2017-06-18
 306068 2017-06-19
 318727 2017-06-20
 331000 2017-06-21
 338890 2017-06-22
 341160 2017-06-23
 317617 2017-06-24
 248929 2017-06-25
 290740 2017-06-26
 321083 2017-06-27
 316000 2017-06-28
 313277 2017-06-29
 302847 2017-06-30
----


== Project 3

Use R to revisit these questions.  They can each be accomplished with 1 line of code.

Question 1.

As in Project 1, question 2:  In the year 2005, did United or Delta have more flights?

Question 2.

As in Project 2, question 2a:  Restricting attention to weekends (only), what was the average arrival delay (in minutes) for flights in 2005?

Question 3.

As in Project 1, question 3:  In June 2017, what is the distribution of the number of passengers in the taxi cab rides?

Question 4.

As in Project 2, question 4a:   What is the average distance of a taxi cab ride in New York City in June 2017?

Question 5.

Use the tapply function to find the following:

a.  The average number of passengers (on taxi cabs rides) for each day of June 2017.

b.  The average distance (on taxi cabs rides) for each day of June 2017.

c.  The average distance (on airplane flights) for each day of 2005.

d.  The average arrival delay (on airplane flights) for each day of 2005.

In the following questions, we use our UNIX knowledge to help extract some of the data, because we do not want to import all of the data into R.  We want to start combining some of our knowledge about various tools.

Question 6.

Use UNIX to make a new file that contains the departure delays of the flights from `IND` to `ORD`. What is the average departure delay on flights from IND to ORD?  Double-check your work, by analyzing the file created in question 6ab in Project 1, and by comparing to your awk solution in question 3 in Project 2.

Question 7.

a.  Use UNIX to make a new file that contains the distances of every taxi cab ride in the New York City yellow cab files (across all months and years).  It should have 1 distance per line.

b.  What is the mean and standard deviation of the distance of these taxi cab rides?

Question 8.

a.  Use UNIX to extract the information about how many flights (across all years) occur with each airline (i.e., with each `UniqueCarrier`).  You can tabulate these results in UNIX or in R.

b.  Make a dotchart in R that displays this data.

Question 9.

Use the data about the airports available from the http://stat-computing.org/dataexpo/2009/supplemental-data.html[supplemental data] of the ASA DataExpo 2009 to make a map of the contiguous portion of the United States, displaying all of the airports.

Question 10.

Make an analogous map of Indiana with its airports.


