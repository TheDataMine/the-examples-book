= STAT-LLC Fall 2014 STAT 29000 Projects

== Project 1

Question 1.

During which pair of years did the level of Lake Huron rise the most?
The data to use is from the built-in `LakeHuron` data set.
(E.g., during 1875 to 1876, Lake Huron rose 1.48 feet.)  It might help to use the `diff` command.

Question 2.

a. What is the average duration of an eruption in the `geyser` dataset in the `MASS` library?

b. What were the 10 longest durations?

c. How many durations were 3 minutes or longer?
(You do not need to install the `MASS` library; it is installed already.  You do, however, need to load the `MASS` library.)

Question 3.

a.  Which car(s) in the `mtcars` data set had the highest gas mileage?

b.  Which car(s) had the highest horsepower?

c.  Which car(s) had the shortest (i.e., fastest) 1/4 mile time?

d.  How many cars had manual transmission?

e.  How many cars had manual transmission and also six cylinders?

Question 4.

a.   Which states are (strictly) larger in population than Indiana but (strictly) smaller in population than Pennsylvania, according to the data in the `state` data set?
Hint: You can get the state populations using `state.x77[,"Population"]`.

b.   Which states are (strictly) larger in land area than Indiana but (strictly) smaller in land area than Pennsylvania, according to the data in the `state` data set, as listed in `state.x77[,"Area"]`?

Question 5.

If `Z` is a standard normal random variable, we know that `Z` has average 0 and variance 1.  Use `R` to simulate:

a. the value of the average of `|Z|`, and

b. the value of the variance of `|Z|`.

Here, `|Z|` is just the absolute value of `Z`.

Question 6.

Write a function called `countas` that takes a sequence of words and returns the number of words that have 1 or more `a`s. For instance, `countas(  c("ate", "hello", "duolingo", "pat", "aa")  )` should return the value 3.  Hint:  It might help to use the `grep` function.

Question 7.

a.  Write a function called:  `firstthree` that returns the location of the first occurrence of 3 in a vector.  For instance, `firstthree( c(-2.5,3,3,0.001,22,5,7,19,3,17) )` should return the value 2.

b.  Write a function called:  `thirdthree` that returns the location of the third occurrence of 3 in a vector.  Ffor instance, `thirdthree( c(-2.5,3,3,0.001,22,5,7,19,3,17) )` should return the value 9.

Question 8.

Write a function called:  `topfive` that returns the most common five values in a vector, along with the counts for each of the 5 values.

Question 9.

a. Euler's number is 2.718281828459...  Euler's number is defined as `1 + 1/1 + 1/(1*2) + 1/(1*2*3) + 1/(1*2*3*4) + 1/(1*2*3*4*5) + ...` Find a good way to calculate this in `R`, with few keystrokes. If you subtract 2.718281828459 from your estimate, you should get something very small, e.g., roughly `4.5 * 10^{-14}.`

b.  Find a good way to approximate the value of Pi, using only the fact that `Pi^2 / 6 = 1/1^2 + 1/2^2 + 1/3^2 + 1/4^2 + 1/5^2 + 1/6^2 + 1/7^2 + ....`

Question 10.

a. The triangular numbers are: `1, 3, 6, 10, 15, 21, 28, 36, 45, 55, ...` See http://oeis.org/A000217 Find an efficient way to compute, in `R`, the first 100 such numbers.  Does your method extend to the first 1000 such numbers too?

b. The tetrahedral numbers are: `1, 4, 10, 20, 35, 56, 84, 120, 165, 220, ...` See: http://oeis.org/A000292 Find an efficient way to compute, in `R`, the first 100 such numbers.  Does your method extend to the first 1000 such numbers too?

== Project 2

Question 1.

Consider the Columbia River Estuary dataset discussed in the `week 2 notes`

a.  Download the data set (we no longer need to do this).

b.  Import the `saturn03.240.A.CT_2012_06_PD0.csv` data set into `R`, using the `read.csv` function.

c.  Use the `strptime` function to convert the first column of the data into numerical times that `R` can easily handle.

Question 2.

a.  What is the most common time (in seconds) between consecutive measurements, in the data set?  How often is the data sampled with this exact difference in time, between consecutive measurements?

b.  What is the mean time between consecutive measurements?  Why is this significantly different from the most common time, found in part `2a` above?

Question 3.

a.  Suppose that we treat "15 seconds" as a threshold in consecutive time measurements, i.e., if the machine goes more than 15 seconds without taking a measurement, we consider that the machine is temporarily broken/clogged/stuck/etc.  With this level of threshold, how many times did this particular machine (at this particular location) get stuck during June 2012?

b.  How long is longest duration when the machine was broken?  When did this occur? Specifically: when did it break, and when did it start working properly again?

c.  Find the ten longest durations for when the machine was broken; just give each such measurement in seconds.

Question 4.

a. Does the device which measures the electrical conductivity ever give a false reading?  If so, when?  Give the specific times (e.g., the day(s), hours, minutes, seconds), when this occurs in June, for each such occurrence.

b. Are any of these times in `4a` the same as the one (unique) time when the temperature device gave a false reading?  (We saw, in the notes, that the temperature device had one false reading.)

c.  Does the device which measures the salinity ever give a false reading?  What evidence to you have to support this claim?

Question 5.

a.  Repeat the questions from `2a`/`2b`/`3a`/`3b`/`3c`, but now use the data set from the same point on the Columbia River Estuary but at the depth of `8.2m` (the data from the questions above was measured at `2.4m` below the surface).  The data set from `8.2m` below the surface is available at `saturn03.820.A.CT_2012_06_PD0.csv`.

b.  Does the longest time in which the machine was broken in `3b` (at depth `2.4m`) correspond roughly to the same longest time in which the machine was broken in this current data set, at depth `8.2m`?  For this longest time interval, what are the times (at depth `8.2m`), when the machine did break, and when did it start working properly again?

c.  Make a plot of the temperature data at depth `8.2m`.  There is exactly one false reading in which the temperature is too high, and exactly one false reading in which the temperature is too low.  Be sure to remove these points before plotting.

Question 6.

a.  We also have data from depth `13m` below the surface in the file `saturn03.1300.R.CT_2012_06_PD0.csv`.  Import this data into `R`.

b.  Is the water temperature generally highest, on average, at depth `2.4m`, `8.2m`, or `13m` below the surface?  Does your answer make intuitive sense?

Question 7.

a.  What is the average salinity of the water at depth `2.4m`?  At depth `8.2m`?  At depth `13m`?  What about the variance of the salinity at all 3 depths?  Be sure to remove any outliers, when appropriate.

b.  At depth `13m`, make a plot of time versus salinity.

c.  As we saw in `7b`, much more data is available during the first two weeks of June, as opposed to the second two weeks of June.  Make a revised plot, showing only the time versus salinity from the start of the day on June 6, through the end of the day on June 12 (i.e., for a full 7-day period).  How many cycles of the salinity do you think you see on this plot?  Is there a natural reason for this number of cycles?

Question 8.

At depth `2.4m`, what fraction of the temperature data points are between 10 and 12?  Between 12 and 14?  Between 14 and 16?  Between 16 and 18?  Use the `tapply` function to answer all four of these questions with one line of code.

Question 9.

At depth `2.4m`, what is the average temperature between the start of the day on June 1 and the end of the day on June 7?

What is the average temperature between the start of the day on June 8 and the end of the day on June 14?

What is the average temperature between the start of the day on June 15 and the end of the day on June 21?

What is the average temperature between the start of the day on June 22 and the end of the day on June 28?

Use the `tapply` function to answer all four of these questions with one line of code.

[Note: The original problem statement had an off-by-one typographical error on some of the dates.]

Question 10.

At depth `13m`, how many data points have salinity greater than 12 and temperature greater than 14?

How many data points have salinity greater than 12 and temperature at most 14?

How many data points have salinity at most 12 and temperature greater than 14?

How many data points have salinity at most 12 and temperature at most 14?

Use the `tapply` function to answer all four of these questions with one line of code.

Hint:  You will need to embed a `list` into your `tapply`, as we did in the notes file `CO2examplecontinued.R` (the second CO2 example).


