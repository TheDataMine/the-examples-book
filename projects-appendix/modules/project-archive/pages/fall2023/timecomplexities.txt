=== Question 5 (2 pts)
[upperalpha]
.. Write a list of the big O time complexities for each of the functions below.
.. Write 2-3 sentences explaining why it is difficult to determine the time complexity of a function without knowing the time complexities of the sub-functions inside it.

Let's briefly discuss time complexity, a concept of huge importance in computer science. While an in-depth discussion of time complexity is outside the scope of this course, a working understanding of its core concepts is an invaluable skill to have in this modern age. 

Time complexity, at heart, is a measure of the efficiency of our program. This may be best described through an example, but if you feel the need for a more formal explanation, https://towardsdatascience.com/understanding-time-complexity-with-python-examples-2bda6e8158a7[here] is some reading that may appeal to you.

Now for our example. Let's say we create a function to sort a list of numbers in ascending order, via some arbitrary algorithm (there are many that would work). When we give the function a list of 4 numbers to sort, it takes 8 seconds. Then, when we double the size of the list the amount of time doubles (8 numbers, 16 seconds). If we double the size again, the amount of time doubles again (16 numbers, 32 seconds). Because the amount of time the function takes to run is linearly correlated with the size of the list it is given, we say it runs in "linear time". If, however, doubling the size of the list instead quadrupled the amount of time it took to run, we would say it runs in "quadratic time", as the relationship between the size of the argument and the time it takes to run is quadratic.

When people discuss time complexity, you will often hear them use terms like "Big/Little O", "Big/Little Theta", and "Big/Little Omega". These are all different ways of describing the time complexity of a function, and are all related to one another. For the purposes of this course, we will be using "Big O" exclusively, as it is the most common and easiest to understand.

Big O time complexity is defined as the worst possible time complexity that the function can have, given _n_ arguments (This is an oversimplification of the rather complex mathematical definition of Big O). For example, if we have a function that takes a list of numbers and returns the largest number in the list, we would say that it has a time complexity of O(n), as the worst possible time complexity it could have is linear (if the largest number is the last number in the list, we have to go through the whole list before finding it).

After reading the above example and article, feel free to do some more research on your own. Then, for each of the below functions, give the Big O time complexity of each function. If you are unsure, feel free to ask on Piazza, or do some more research on your own. If you are still unsure, make your best guess and explain your reasoning.

[NOTE]
====
You may assume that any sub-functions used within a function have a constant time complextiy (i.e. O(1)), and thus will not affect the overall time complexity of the function.
====

[source,ipython]
----
def find_first_three(num_list):
    return num_list[0], num_list[1], num_list[2]
----

[source,ipython]
----
def find_biggest(num_list):
  biggest = -999
  for i in range(0,len(num_list)):
    if num_list[i] > biggest:
      biggest = num_list[i]
  return biggest
----

[source,ipython]
----
def double_looping(num_list):
    for i in range(0,len(num_list)):
        for j in range(0,len(num_list)):
            print(f"Loop {i}: {num_list[j]}")
    return
----

For the last portion of this question, think about what happens when a function calls a sub-function and how this might affect time complexity. Sub-functions also have a time complexity. How does this factor into the overall complexity of the main function? In order to get credit for this portion, write 2-3 sentences explaining why it is difficult to determine the time complexity of a function without knowing the time complexities of the sub-functions inside it.

Going forward, try and keep the time complexity of the functions you are writing in mind as you write them. While this is not _as_ important in data science, as many of the functions you write are designed to be run only a few times, it can still help greatly improve the speed of your code, saving you time on your project (in addition to being a skill employers value!).

.Items to submit
====
- The time complexities of the 3 functions above.
- A 2+ sentence explanation about how the time complexity of a function is affected by the time complexities of the sub-functions it calls.
====

