= 301 Project 01 - Intro to ML - Using Anvil

== Project Objectives

Get comfortable  using the Anvil platform and running python code in jupyter notebooks.
Also, begin using basic functions of the pandas library.

.Learning Objectives
****
- Create and use Anvil sessions
- Create jupyter notebooks
- Load dataset with pandas
- Basic data manipulation with pandas
****

== Dataset

This project will use the following dataset:
- `/anvil/projects/tdm/data/Iris.csv`

== Questions

=== Question 1 (2 points)

Let's start out by starting a new Anvil session. If you do not remember how to do this, please read through https://the-examples-book.com/projects/fall2024/10100/10100-2024-project1[TDM 101's project 1].

Once you have started a new Anvil session, download https://the-examples-book.com/projects/_attachments/project_template.ipynb[the project template] and upload it. Then, open this template in jupyter notebook. Save it as a new file with the following naming convention: `lastname_firstname_project#.ipynb`. For example, `doe_jane_project1.ipynb`.

[NOTE]
====
You may be prompted to select a kernel when opening the notebook. We will use the `seminar` kernel for 301 projects. You are able to change the kernel by clicking on the kernel dropdown menu and selecting the appropriate kernel if needed.
====

To make sure everything is working, run the following code cell:
[source,python]
----
print("Hello, world!")
----

Your output should be `Hello, world!`. If you see this, you are ready to move on to the next question.
.Deliverables
====
- Output of running the code cell
====

=== Question 2 (2 points)

Now that we have our jupyter notebook set up, let's begin working with the pandas library.

Pandas is a python library that allows us to work with datasets in tabular form. There are functions for loading datasets, manipulating data, etc.

To start out with, let's load the Iris dataset that is located at `/anvil/projects/tdm/data/Iris.csv`.

To do this, you will need to import the pandas library and use the `read_csv` function to load the dataset.

Run the following code cell to load the dataset:
[source,python]
----
import pandas as pd

df = pd.read_csv('/anvil/projects/tdm/data/Iris.csv')
----

[NOTE]
====
pandas is commonly imported as `pd` for brevity. This is a common convention in the python community. Similarly, `df` (short for dataframe) is often used as a variable for pandas dataframes. It is not required for you to follow either of these conventions, but it is good practice to do so.
====

Now that our dataset is loaded, let's take a look at the first 5 rows of the dataset. To do this, run the following code cell:
[source,python]
----
df.head()
----

[NOTE]
====
The head function is used to display the first n rows of the dataset. By default, n is set to 5. You can change this by passing an integer to the function. For example, `df.head(10)` will display the first 10 rows of the dataset. This function is useful for quickly inspecting the dataframe to see what the data looks like.
====

.Deliverables
====
- Output of running the code cell
====

=== Question 3 (2 points)

An important aspect of our dataframe for machine learning is the shape (rows, columns). As you will learn later, the shape will help us determine what kind of machine learning model will be the best fit, as well as how complex it may be.

To get the shape of the dataframe, run the following code cell:
[source,python]
----
df.shape
----

[NOTE]
====
There are multiple ways to get the number of rows and columns in a dataframe. The shape attribute is the most common way to do this.
However, an alternative way to get the number of rows is `len(df.index)`, which returns the length of the rows in the dataframe. Similarly, an alternative way to get the number of columns is `len(df.columns)`, which returns the length of the columns in the dataframe. The shape attribute is preferred because it is more concise and returns both the number of rows and columns in one call.
====

This returns a tuple in the form (rows, columns).
.Deliverables
====
- How many rows are in the dataframe?
- How many columns are in the dataframe?
====

=== Question 4 (2 points)

Now that we have loaded the dataset, let's investigate how we can manipulate the data.

One common operation is to select a subset of the data. This is done using the `iloc` function, which allows us to index the dataframe by row and column numbers.
[NOTE]
====
The `iloc` function is extremely powerful. It can be used in way too many ways to list here. For a more comprehensive list of how to use `iloc`, please refer to https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html[the official pandas iloc documentation].
====

To select the first n rows of the dataframe, we can use the `iloc` function with a slice: `df.iloc[:n]`.

Write code to select the first 10 rows of the dataframe from Question 3 into a new dataframe called `df_subset`. Print the shape of `df_subset` to verify that you have selected the correct number of rows.

.Deliverables
====
- Output of printing the shape of `df_subset`
====

=== Question 5 (2 points)

Another common operation is to remove column(s) from the dataframe. This is done using the `drop` function.

[NOTE]
====
Similarly to the `iloc` function, the `drop` function is extremely powerful. For a more comprehensive list of how to use `drop`, please refer to https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html[the official pandas drop documentation].
====

The most readable way to drop a column is by dropping it by name. To drop column(s) by name, you can use the following syntax: `df.drop(['column1_name', 'column2_name', ...], axis=1)`. The `axis=1` argument tells pandas to drop columns, not rows.

Write code to drop the `Id` column from the dataframe into a new dataframe called `df_without_id`. Print the shape of the dataframe to verify that the column has been removed.

.Deliverables
====
- Output of printing the shape of the dataframe after dropping the `Id` column
====


== Submitting your Work

Once you have completed the questions, save your jupyter notebook. You can then download the notebook and submit it to Gradescope.

.Items to submit
====
- firstname_lastname_project1.ipynb
====

[WARNING]
====
You _must_ double check your `.ipynb` after submitting it in gradescope. A _very_ common mistake is to assume that your `.ipynb` file has been rendered properly and contains your code, markdown, and code output even though it may not. **Please** take the time to double check your work. See https://the-examples-book.com/projects/submissions[here] for instructions on how to double check this.

You **will not** receive full credit if your `.ipynb` file does not contain all of the information you expect it to, or if it does not render properly in Gradescope. Please ask a TA if you need help with this.
====