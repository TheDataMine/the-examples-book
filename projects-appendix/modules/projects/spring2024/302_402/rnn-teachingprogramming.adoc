= Recurrent Neural Networks (RNN)

Recurrent Neural Networks are a type of neural network that uses a bidirectional model architecture, where outputs from nodes affect the incoming inputs to some extent (in contrast to the well known feedforward architecture that neural nets have traditionally used). There are many different styles of implementation, yet they often incorporate sequential or language related data to produce models that can remember and learn from the data and dynamically to decide what information matters during learning and what doesn't.

== Common Applications

=== Common Problem Types

- NLP
- Time Series
- Music/Sound/Audio
- Biological/Genetic

== A Brief History

With roots in the 1920's, Amari (1972) is generally credited with being the first to make RNN's *adaptive*, that is, learn to change its outputs given its inputs by changing connection weights. Slow and steady developments in the 70's and 80's gave rise to one of the most popular RNN derivatives, the LSTM ("Long Short-Term Memory"). By 2016, LSTM models accounted for utilizing over a quarter of the total computational resources allotted for neural net inference at Google.

https://arxiv.org/pdf/2212.11279.pdf[Learn more from our source about the history of RNN's (and NN in general!)]

== Code Examples

NOTE: All of the code examples are written in Python, unless otherwise noted.

=== Containers

TIP: These are code examples in the form of Jupyter notebooks running in a container that come with all the data, libraries, and code you'll need to run it. https://the-examples-book.com/starter-guides/data-engineering/containers/using-data-mine-containers[Click here to learn why you should be using containers, along with how to do so.]

TIP: Quickstart: https://docs.docker.com/get-docker/[Download Docker], then run the commands below in a terminal. 

==== Time Series RNN

A great example from the Tensorflow authors building an RNN using time series data.

[source,bash]
----
#pull container, only needs to be run once
docker pull ghcr.io/thedatamine/starter-guides:time-series-rnn

#run container
docker run -p 8888:8888 -it ghcr.io/thedatamine/starter-guides:time-series-rnn
----

==== LSTM (Long Short-Term Memory)

An implementation of an LSTM model trained on stock data to predict what the value will be in the near future.

[source,bash]
----
#pull container, only needs to be run once
docker pull ghcr.io/thedatamine/starter-guides:lstm

#run container
docker run -p 8888:8888 -it ghcr.io/thedatamine/starter-guides:lstm
----

Need help implementing any of this code? Feel free to reach out to mailto:datamine-help@purdue.edu[datamine-help@purdue.edu] and we can help!

== Resources

All resources are chosen by Data Mine staff to be of decent quality, and most if not all content is free. 

=== Websites

- https://www.ibm.com/topics/recurrent-neural-networks[Recurrent Neural Networks (IBM)]
- https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks[Recurrent Neural Networks Cheatsheet (Stanford)]
- https://karpathy.github.io/2015/05/21/rnn-effectiveness/[The Unreasonable Effectiveness of Recurrent Neural Networks (Andrej Karpathy)]
- https://colah.github.io/posts/2015-08-Understanding-LSTMs/[Understanding LSTM's (Christopher Olah)]
- https://towardsdatascience.com/recurrent-neural-networks-rnns-3f06d7653a85[Recurrent Neural Networks (Towards Data Science)]
- https://www.mathworks.com/discovery/rnn.html[What is a Recurrent Neural Network? (MathWorks)]

=== Videos

- https://www.youtube.com/watch?v=AsNTP8Kwu80[Recurrent Neural Networks (RNNs), Clearly Explained!!! (StatQuest With Josh Starmer, ~16 minutes)]
- https://www.youtube.com/watch?v=YCzL96nL7j0[Long Short-Term Memory (LSTM), Clearly Explained (StatQuest With Josh Starmer, ~21 minutes)]
- https://www.youtube.com/watch?v=b61DPVFX03I[What is LSTM (Long Short Term Memory)? (IBM, ~8 minutes)]
- https://www.youtube.com/watch?v=LHXXI4-IEns[Illustrated Guide to Recurrent Neural Networks: Understanding the Intuition (The A.I. Hacker - Michael Phi, ~10 minutes)]
- https://www.youtube.com/watch?v=WCUNPb-5EYI[Recurrent Neural Networks (RNN) and Long Short-Term Memory (LSTM) (~25 minutes)]
- https://www.youtube.com/watch?v=Y2wfIKQyd1I[What is Recurrent Neural Network (RNN)? (~16 minutes)]
- https://www.youtube.com/watch?v=DFZ1UA7-fxY[Recurrent Neural Networks : Data Science Concepts (~27 minutes)]

=== Books

- https://www.statlearning.com[Introduction to Statistical Learning (ISL)]
- https://purdue.primo.exlibrisgroup.com/permalink/01PURDUE_PUWL/uc5e95/alma99170200340801081[Recurrent neural networks: from simple to gated architectures (2022)]
- https://purdue.primo.exlibrisgroup.com/permalink/01PURDUE_PUWL/uc5e95/alma99170398531201081[Recurrent neural networks: concepts and applications (2023)]

=== Articles

- https://arxiv.org/pdf/2212.11279.pdf[The Road To Modern AI (2022)]
- https://purdue.primo.exlibrisgroup.com/permalink/01PURDUE_PUWL/5imsd2/cdi_crossref_primary_10_1162_neco_1997_9_8_1735[Long Short-Term Memory (1997)]
- https://purdue.primo.exlibrisgroup.com/permalink/01PURDUE_PUWL/5imsd2/cdi_crossref_primary_10_1016_j_petrol_2019_106682[Time-series well performance prediction based on Long Short-Term Memory (LSTM) neural network model (2020)]
- https://purdue.primo.exlibrisgroup.com/permalink/01PURDUE_PUWL/5imsd2/cdi_doaj_primary_oai_doaj_org_article_e6777fc0a9164c74997b527270e53e33[Long Short-Term Memory Neural Networks for Online Disturbance Detection in Satellite Image Time Series (2018)]
- https://web.stanford.edu/~jurafsky/slp3/9.pdf[RNN's and LSTM's (2023)]
- https://arxiv.org/pdf/1909.09586.pdf[Understanding LSTM a tutorial into Long Short-Term Memory Recurrent Neural Networks (2019)]
- https://purdue.primo.exlibrisgroup.com/permalink/01PURDUE_PUWL/5imsd2/cdi_crossref_primary_10_1109_T_C_1972_223477[Learning Patterns and Pattern Sequences by Self-Organizing Nets of Threshold Elements (1972)]