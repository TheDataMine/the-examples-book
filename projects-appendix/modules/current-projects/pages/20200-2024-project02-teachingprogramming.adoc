= TDM 30200: Project 02 -- 2024

**Motivation:** Web scraping is the process of taking content off of the internet. Typically this goes hand-in-hand with parsing or processing the data. In general, scraping data from websites has always been a popular topic in The Data Mine. We will use the website of "books.toscrape.com" to practice scraping skills

**Context:** In the previous project we gently introduced XML and xpath parse a XML document. In this project, we will learn about web scraping, scrape data from a website using BeautifulSoup

**Scope:** Python, web scraping, selenium, BeautifulSoup

.Learning Objectives
****
- Use Selenium and XPath expressions to efficiently scrape targeted data.
- Use BeautifulSoup to scrape data from web pages
****

Make sure to read about, and use the template found xref:templates.adoc[here], and the important information about projects submissions xref:submissions.adoc[here].


 
== Questions

=== Question 1 (2 pts)
 

.. Please use `selenium` to get and display the book with book's title is "Something More Thank This" in the Romance books page
.. At same page, try to find book titled "Black Dust" then `click` this book link and then scrape and print book information: product description, upc and availability

Take a look at the page source -- do you think clicking the book link was needed in order to scrape that data? Why or why not?

[NOTE]
====
You may get more information about `xpath` here: https://www.w3schools.com/xml/xpath_intro.asp [xpath]
====
 

=== Question 2 (2 pts)
 
.. Please use BeautifulSoup library to get and display all categories' names from the homepage of the website

[TIP]
====

* BeautifulSoup is a python library. You can use it to extract data from HTML or XML files. You may find more BeautifulSoup information here:  https://www.crummy.com/software/BeautifulSoup/bs4/doc/
* Use BeautifulSoup for this question
[source,python]
from bs4 import BeautifulSoup
====
[TIP]
====
* You can parse the page with BeautifulSoup
[source,python]
bs = BeautifulSoup(driver.page_source,'html.parser')
====
[TIP]
====
* Review the page source of the website's homepage, including categories located at the sidebar.  The BeautifulSoup "select" method is useful to get names, like this:

[source,python]
categories = [c.text.strip() for c in bs.select('.nav-list li a')]
====


[source,python]
----
import time
from selenium import webdriver
from selenium.webdriver.firefox.options import Options
from selenium.webdriver.common.by import By
 
firefox_options = Options()
firefox_options.add_argument("--window-size=810,1080")
# Headless mode means no GUI
firefox_options.add_argument("--headless")
firefox_options.add_argument("--disable-extensions")
firefox_options.add_argument("--no-sandbox")
firefox_options.add_argument("--disable-dev-shm-usage")

driver = webdriver.Firefox(options=firefox_options)

driver.get("https://books.toscrape.com")
e_t = driver.find_element("xpath",'//article[@class="product_pod"]/h3/a')
e_p = driver.find_element("xpath",'//p[@class="price_color"]')
fst_b_t = e_t.text
fst_b_p =e_p.text

# find book entitled "how music works"
book_link = driver.find_element(By.LINK_TEXT, "How Music Works")
book_link.click()
time.sleep(5)

#scrape and print book information : product description, UPC and availability
product_desc=driver.find_element(By.CSS_SELECTOR,'meta[name="description"]').get_attribute('content')
product_desc
table = driver.find_element(By.XPATH, "//table[@class='table table-striped']")
upc= table.find_element(By.XPATH, ".//th[text()='UPC']/following-sibling::td[1]")
upc_value = upc.text
upc_value

availability = table.find_element(By.XPATH, ".//th[text()='Availability']/following-sibling::td[1]")
availability_value = availability.text
availability_value
driver.quit()
----

=== Question 3 (2 pts)

.. Please get first page books for category "Mystery". You will need to display the list of book objects with book titles, book price and book availability from the first webpage.

[TIP]
====
* Review the page source, you may find one "article" tag holds one book information. You may use find_all to find all "article" tags, like

[source, python]
articles=bs.find_all("article",class_="product_pod") 
====

[TIP]
====
* You may create an object to hold the book information, like:
[source,python]
book = {
    "title":title,
    "price":price,
    "availability":availability
}
====

[TIP]
====
* You may use a loop to go through the books, like
[source,python] 
for article in articles:
    title = article.h3.a.attrs['title']
    price = article.find('p',class_='price_color').text
    availability = article.find('p',class_='instock availability').text
# create a book object with the extract information
    ....
====
[TIP]
====
* You may need a list to hold all book objects, and add all books to it, like
[source,python]
all_books=[]
...
all_books.append(book)
====
[NOTE]
====
* You may use different ways to solve the question, like use function "map" etc.  
====

=== Question 4 (2 pts)

 
.. Please update the code from question 3 to get book list tht include the seconde page of the category "Mystery" 

[TIP]
====
* Look for pagination link "next" 
====

 

Project 02 Assignment Checklist
====
* Jupyter Lab notebook with your code, comments and output for the assignment
    ** `firstname-lastname-project02.ipynb` 
* Submit files through Gradescope
====

[WARNING]
====
_Please_ make sure to double check that your submission is complete, and contains all of your code and output before submitting. If you are on a spotty internet connection, it is recommended to download your submission after submitting it to make sure what you _think_ you submitted, was what you _actually_ submitted.

In addition, please review our xref:projects:current-projects:submissions.adoc[submission guidelines] before submitting your project.
====