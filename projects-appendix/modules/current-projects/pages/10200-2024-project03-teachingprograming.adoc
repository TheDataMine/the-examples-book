= TDM 10200: Project 3 -- 2024

**Motivation:** Learning about Big Data. When working with large data sets, it is important to know how we can use control flow to find our information, a little bit at a time, without reading in all of the files at once. Control flow is the order that your code runs
 

**Scope:** Python, Control Flow, if statements, for loops

== Dataset(s)

/anvil/projects/tdm/data/noaa

== Readings and Resources

[NOTE]
====

- Make sure to read about, and use the template found xref:templates.adoc[here], and the important information about projects submissions xref:submissions.adoc[here].
- Please review https://the-examples-book.com/programming-languages/python/control-flow[this] Examples Book content about Control Flow
====

== Questions

=== Question 1 (2 pts) 

[loweralpha]

.. Explore the files at the provided data set folder. Find out how many years include in the data set. Briefly describe a file's content
.. Import the library `pandas` as `pd`, and import `Path` from `pathlib`
.. Create a list named "files", to hold "Path" objects from "1980.csv" to "1983.csv" in the data set folder using "list comprehension". You may refer to the following sample code that created list with a for loop. Modify it to use "List comprehensions"  
+
[TIP]
====
- Following is the sample code that will return a "Path" object for file 1750.csv
[source,python]
Path("/anvil/projects/tdm/data/noaa/1750.csv")

- You may use a for loop to create a list of Path objects like
[source,python]
files=[]
for year in range (1980, 1983):
    file= Path(f'/anvil/projects/tdm/data/noaa/{year}.csv')
    files.append(file)
print(files)
====

=== Question 2 (2 pts)

.. Calculate how many records in file "1980.csv"
+
[TIP]
====
- The following is the sample code to calculate records in one sample file object named "file"
[source, python]
with open(file,"r") as f:
    count =0
    for line in f:
        count+=1
print(f'There are {count} records in the {file}')

- Output will be like (if for "1980.csv")

There are 33923709 records in the /anvil/projects/tdm/data/noaa/1980.csv
====
.. Calculate how many records in total for all 3 files from "1980.csv" to "1983.csv" , use "files" list you created 

[TIP]
====
- You may use a for loop to iterate "files" object like
[source,python]
for file in files:
...# body of the for loop
====


=== Question 3 (2 pts)

.. Run the following statement to read in the first file of the "files" object from previous questions to a DataFrame. Display the column names for the file_df. Describe your finding from the output.

[source,python]
----
file_df = pd.read.csv(files[0])
----
.. Please Modify the statement to recreate the file_df to correct the issue you may find from question a. What is the column names now?

[TIP]
====
"header=None" argument will be useful 
====

.. Now let us add column titles for each column starts from first column as "id","date","element_code","value","mflag","qflag","sflag" and "obstime" respectively while read files to DataFrames. Name the list of DataFrames "file_DFs", it will hold 3 DataFrames from "1980.csv" to "1983.csv". Refer to the following sample code for reading in the first file, add a "for" loop above it to read in all 3 files 
+
[source,python]
file_df = pd.read_csv(files[0],names = ["id","date","element_code","value","mflag","qflag","sflag","obstime"])
====
.. Use a "for" loop to display all DataFrames' columns name in file_DFs list. You may refer to the following code that how to find one DataFrame's columns. Add a "for" loop to get all 3 DataFrames' columns (They should be identical)

[TIP]
====
[source,python]

column_names = file_df.columns
print(column_names)
====

=== Question 4 (2 pts)

Let's look at the column "element_code", Use loop to do the following questions for all 3 DataFrames

.. Print out the unique elements of column "element_code"
.. Find the number of times that "SNOW" occurs in the "element_code" column.

[TIP]
====
- unique() will be useful to calculate unique values
- You may use different methods to find the number of "SNOW" like 'len()',value_counts(),sum() etc.
====
 

=== Question 5 (2 pts)

Now let us practice to use "chunksize" feature for big data. You may refer to https://www.geeksforgeeks.org/how-to-load-a-massive-file-as-small-chunks-in-pandas/[this] document to get more informaiton about chunksize. 
.. Try to run the following 2 program to find the number of times that "SNOW" occurs in the "element_code" column from year 1980 to year 1983. Explain your understanding of "chunkszie"


[source, python]
----
import pandas as pd
import pandas as pd
from pathlib import Path
files=[]
for year in range (1980, 1983):
    file= Path(f'/anvil/projects/tdm/data/noaa/{year}.csv')
    files.append(file)
#print(files)
count = 0
for file in files:
    for df in pd.read_csv(file,names=["id","date","element_code","value","mflag","qflag","sflag","obstime"],chunksize =10000):
        count += len(df[df['element_code'] == 'SNOW'])

print(count)
----
 
[source,python]
----
import pandas as pd
from pathlib import Path
files=[]
for year in range (1980, 1983):
    file= Path(f'/anvil/projects/tdm/data/noaa/{year}.csv')
    files.append(file)
#print(files)
count = 0
for file in files:
    for df in pd.read_csv(file,names=["id","date","element_code","value","mflag","qflag","sflag","obstime"],chunksize =10000):
        for index, row in df.iterrows():
            if row['element_code'] == 'SNOW':
                count += 1
print(count)
----


====
Project 03 Assignment Checklist
====
* Jupyter Lab notebook with your code, comments and output for the assignment
    ** `firstname-lastname-project03.ipynb`.
* Python file with code and comments for the assignment
    ** `firstname-lastname-project03.py`

* Submit files through Gradescope
==== 

 

[WARNING]
====
_Please_ make sure to double check that your submission is complete, and contains all of your code and output before submitting. If you are on a spotty internet connection, it is recommended to download your submission after submitting it to make sure what you _think_ you submitted, was what you _actually_ submitted.
                                                                                                                             
In addition, please review our xref:submissions.adoc[submission guidelines] before submitting your project.
====
