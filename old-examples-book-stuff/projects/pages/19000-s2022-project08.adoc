= STAT 19000: Project 1 -- Spring 2022

**Motivation:** 

**Context:** 

**Scope:** 

.Learning Objectives
****
- 
****

Make sure to read about, and use the template found xref:templates.adoc[here], and the important information about projects submissions xref:submissions.adoc[here].

== Dataset(s)

The following questions will use the following dataset(s):

- `/depot/datamine/data/stackoverflow/unprocessed/*`

== Questions

=== Question 1

Take a look at the datasets in `/depot/datamine/data/stackoverflow/unprocessed/`. There are a variety of ways this dataset could be cleaned up. In this project, we will clean these datasets up a bit, using `pandas`. 

Read in `2011.csv`. This is a comma-separated dataset. If you want a given csv file to be easy to parse through using a variety of tools, you should first make sure that the delimiter is a comma, and that there is exactly 1 less comma in each row than there is columns. 

Print the columns of the dataset that have commas in their content. Which columns have commas in their content, and how many commas are in each column, total?

.Items to submit
====
- Code used to solve this problem.
- Output from running the code.
====

=== Question 2

It looks like there are a lot of commas in a lot of columns in our dataset. This will make it more difficult to parse this dataset than necessary. Perform the same operations in question (1), but instead of looking for commas in the content of each column, look for semi-colons. 

Given the fact that we want our dataset easy to parse, and given what we know about the usage of commas and semi-colons, what would you suggest we do to clean up this dataset, and why?

Hopefully, you answer was to convert instances of "internal" semi-colons to commas, so there are no remaining "internal" semi-colons, and only commas. This way, you can export the entire dataset to a dsv with semi-colons as the delimiter instead of a comma.

Convert all instances of semi-colons to commas.

[TIP]
====
Double check by re-running your code that checks for semi-colons, to make sure they no longer exist.
====

.Items to submit
====
- Code used to solve this problem.
- Output from running the code.
====

=== Question 3

Great! This is already an excellent start and allows a user to do things like accurately count the number of columns in the dataset in UNIX.

[source,bash]
----
head -n 1 2011.csv | tr ';' '\n' | wc -l
----

You may have noticed some other low-hanging fruit that could be cleaned up. You will notice that some columns have "Unnamed: X" and essentially either contain some value, or are empty. These columns represent a potential answer to the most previous column not named "Unnamed:*". 

Instead of having separate columns for this type of data, instead, let's do the following for each set of "Unnamed:*" columns.

. For each column, if the value is not `pd.NA`, then append it to a comma-separated list of values in the original question column. 
+
[IMPORTANT]
====
Remove commas in the given columns prior to pasting them together with commas.
====
+
. Remove the "Unnamed:*" columns.

[TIP]
====
So, for example, given the following example, we would want the following result.

----
Original question?; Unnamed: 1; Unnamed: 2; Unnamed: 3
answerA;answerB;answerC;answerD
answerA; NA; NA; answerD 
----

----
Original question?
answerA,answerB,answerC,answerD
answerA,answerD
----
====

[IMPORTANT]
====
For this question, perform these operations on a case-by-case basis. I.e., for each instance of a question like this, manually fix the dataset for that question.
====

.Items to submit
====
- Code used to solve this problem.
- Output from running the code.
====

=== Question 4

In the previous question, you were able to greatly simplify the dataset. This is great, however, let's try and automate this process in case we were to ever receive a dataset like this, but with different column names and values. Assume things would be in the same format, so a question with multiple choice answers will have columns called "Unnamed:*", immediately following the column with the actual question.

.Items to submit
====
- Code used to solve this problem.
- Output from running the code.
====

=== Question 5

You now have a much cleaner dataset. One final move would be to remove the first non-header row. You may have noticed this contains some meta-data that we no longer need. 

Once complete, calculate a breakdown of the column "Which languages are you proficient in?". Create a graphic using `matplotlib` showing the number of people who are proficient in the top 10 named languages (in order of most to least).

[TIP]
====
. You can now use string methods on that column to get the languages.
. There is a special `Counter` dict that could be useful.

[source,python]
----
from collections import Counter

my_counter = Counter(['first', 'second', 'third', 'third', 'third'])
my_counter.update(['first', 'first', 'second'])
my_counter
----
====

.Items to submit
====
- Code used to solve this problem.
- Output from running the code.
====

[WARNING]
====
_Please_ make sure to double check that your submission is complete, and contains all of your code and output before submitting. If you are on a spotty internet connection, it is recommended to download your submission after submitting it to make sure what you _think_ you submitted, was what you _actually_ submitted.
====
