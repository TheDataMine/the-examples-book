= Indexing

== Basics and Simple Accessing Methods
It is implausible that you will always need an entire dataset when doing analysis, so being able to efficiently pick subsets of data is an important skill. `pandas` has some vital indexing functions that add logical parameters when working with a `DataFrame` or `Series`. 

{sp}+

=== `[]` and `.`

Using brackets and periods to index in `pandas` are the most basic methods of indexing, and thus allow for simpler subset selection. Both are limited to *column* selection, so you won't be able to select the first row of an object with `df[1]` or `df.1`.

This indexing is done based on the column name -- if we had a column named "columnA", we could select it using `df['columnA']` or `df.columnA`.

Selecting multiple columns is also possible by nesting a list within your brackets: `df[['columnA', 'columnB', 'columnC']]`. This is _not_ possible when using `.` to select attributes -- you are additionally unable to use `.` to select:

* Columns that match names of `pandas` methods -- `max`, `head`, `describe`, etc.
* xref:https://docs.python.org/3/reference/lexical_analysis.html#identifiers[Identifiers], including keywords, whitespace, and literals. _If your column has a space in its name (which many do), you cannot select it with `.`_

{sp}+

=== Slicing

If we consider simple `[]` and `.` indexing to be column selection, we can consider `:` indexing to be row selection. You still start by using brackets, but when `:` is included, the *rows* are now selected instead of columns. _Only_ our rows can be selected when using simple slicing, but as you will soon see, slicing is a tool that is used heavily in more complex indexing.

`:` slicing is inclusive, with an implied 0 for the start and the object's last index implied for the end. Thus, the input `print(df[:])` selects all rows and is the same as `print(df)`. You can add a negative sign to the end index to _exclude_ the last n elements.

If you want to skip certain elements, you can add another colon after the stop index, which would take the following form: `df[0:4:2]`. There is an implied skip of 1 (meaning no skip at all), meaning `print(df[:]) == print(df[::]) == print(df)`. You can add a negative sign in front of the skip parameter to slice the object in reverse order.

{sp}+

=== Examples

For the following, we use the code `np.random.randn(num-rows, num-columns)` to generate a random `DataFrame`. The point is not for the output values to match, but the rows/columns.

==== Return the column `A` from `DataFrame df`.

.Click to see solution
[%collapsible]
====
[source,python]
----
# method 1: []
print(df['A'])
# method 2: .
print(df.A)
----
----
0   -2.676859
1    0.110410
2    1.263104
3    0.161416
4   -0.213868
----
====

==== Return columns `A`, `B`, and `D` from `DataFrame df`.

.Click to see solution
[%collapsible]
====
[source,python]
----
print(df[['A', 'B', 'D']])
----
----
          A         B         D
0  0.461834  0.456688 -1.061509
1  1.003698  1.115509  0.120536
2  0.814746  2.793606 -0.281329
3  0.766533  0.138788  0.479603
4 -0.084290 -0.141935  0.755774
----
====

==== Return every other row in `DataFrame numbers`.

.Click to see solution
[%collapsible]
====
[source,python]
----
print(numbers[::2])
----
----
          A         B         C         D
0 -0.234193 -0.775527 -1.250210  1.421642
2 -3.402812  0.388646  1.199761  1.366917
4 -0.373406  0.868126 -0.063795  1.202232
6 -0.872389  1.717326 -0.709681 -0.339897
----
====

==== Return all of `numbers` except the last 3 rows.

.Click to see solution
[%collapsible]
====
[source,python]
----
print(numbers[:-3])
----
----
          A         B         C         D
0 -0.293664 -0.072110  0.937070  1.611655
1 -0.431300  1.992882  0.175886 -0.777462
2 -0.014344 -0.018958  0.085689  1.749314
3  0.577731 -0.505912  1.576066 -0.688136
4 -1.125129  1.710249  1.230097  0.634027
----
====

{sp}+

== Multi-dimensional Indexing

Fortunately, there are many ways to select multiple dimensions for subsetting, and they generally allow conditionals to further specify the data points you want.

{sp}+

=== `.loc` and `.iloc`

The `loc` method allows for label-based indexing, while `iloc` is primarily integer-based. These are two of the best functions to use when indexing, so we'll be using plenty of examples to demonstrate their versatility.

{sp}+

We can use either `loc` or `iloc` to isolate a single column or `Series`. The differences between the two are strict; if you try to use row/column indices for `loc` or row/column names with `iloc`, you'll get an error.

[source,python]
----
# option 1: loc
just_the_year = myDF.loc[:, 'Year']
# option 2: iloc, matches option 1
just_the_year = myDF.iloc[:, 0]  # Year is the first column.
print(just_the_year)
----
----
0    1987
1    1990
2    1990
3    1990
4    1991
5    1991
6    1991
7    1991
8    1991
----

The same two techniques can both be used for multiple rows and columns as well. Something to keep in mind is that `.iloc` slicing is _exclusive_, contrasting the standard slicing and `.loc` slicing _inclusivity_.

[source,python]
----
year_month = myDF.loc[:, ('Year', 'Month')]
year_month = myDF.iloc[:, 0:2]
print(year_month)
----

----
   Year  Month
0  1987     10
1  1990     10
2  1990     10
3  1990     10
4  1991     10
5  1991     10
6  1991     10
7  1991     10
8  1991     10
----

[source,python]
----
putting_it_together = myDF.loc[0:2, ['Year', 'Month', 'DayofMonth'])
print(putting_it_together)
----

----
   Year  Month  DayofMonth  ...  NASDelay  SecurityDelay  LateAircraftDelay
0  1987     10          14  ...       NaN            NaN                NaN
1  1990     10          15  ...       NaN            NaN                NaN
2  1990     10          17  ...       NaN            NaN                NaN
----

Using `iloc` looks pretty similar. However it should be noted that because the `iloc` indexing is not inclusive it only returns 2 rows instead of 3.  

[source,python]
----
i_want_three_rows = myDF.iloc[0:2, :]
print(i_want_three_rows)
----

----
   Year  Month  DayofMonth  ...  NASDelay  SecurityDelay  LateAircraftDelay
0  1987     10          14  ...       NaN            NaN                NaN
1  1990     10          15  ...       NaN            NaN                NaN
----

Even though the code may look pretty similar the functionality behind `loc` and `iloc` is very different. We can show the difference in behavior if we change the index of the DataFrame: 

[source,python]
----
list_1 = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']
list_2 = ['Apple', 'Banana', 'Coffee', 'Nothing', 'Oatmeal']
list_3 = [1, 3, 6, 8, 1]

column_names = ['day_of_the_week', 'breakfast', 'nonsense']

index_values = [1,1,2,2,3]

myDF = pd.DataFrame(zip(list_1, list_2, list_3), columns=column_names, index=index_values)
print(myDF)
----

----
  day_of_the_week breakfast  nonsense
1          Monday     Apple         1
1         Tuesday    Banana         3
2       Wednesday    Coffee         6
2        Thursday   Nothing         8
3          Friday   Oatmeal         1
----

[source,python]
----
print(myDF.loc[0:2,:])
----

----
  day_of_the_week breakfast  nonsense
1          Monday     Apple         1
1         Tuesday    Banana         3
2       Wednesday    Coffee         6
2        Thursday   Nothing         8
----

In this example the `loc` function is saying that it should return any indexes that have values of 0, 1, or 2 `[0:2]`. For the example DataFrame it only returns the rows with 1 or 2 since we don't have any 0 indicies.  

[source,python]
----
print(myDF.iloc[0:2,:])
----

----
  day_of_the_week breakfast  nonsense
1          Monday     Apple         1
1         Tuesday    Banana         3
----

In comparison the `iloc` will only get the rows in positions 0 and 1. In this case they both happen to have an index of 1. 

You can also index on both rows and columns: 

[source,python]
----
rows_and_columns = myDF.iloc[0:2, 0:2]
print(rows_and_columns)
----

[source,python]
----
rows_and_columns = myDF.loc[0:1, ('day_of_the_week', 'breakfast')]
print(rows_and_columns)
----

----
  day_of_the_week breakfast
1          Monday     Apple
1         Tuesday    Banana
----

The logic that `loc` and `iloc` allow is one of the most impactful features of Pandas indexing. In addition, the logic statements can be chained together. For example, if you wanted to get the rows for `Monday` or that didn't have `Breakfast` you could do the following: 

[source,python]
----
monday_or_breakfast = myDF.loc[(myDF.loc[:, "day_of_the_week"]=="Monday") | (myDF.loc[:, "breakfast"]=="Nothing"), :]
print(monday_or_breakfast)
----

----
  day_of_the_week breakfast  nonsense
1          Monday     Apple         1
2        Thursday   Nothing         8
----

*Note:* in this example the parentheses `()` are critical. Withouth the parentheses Python doesn't know how to evaulate the multiple statements and will error. The following will *not* work: 

[source,python]
----
monday_or_breakfast = myDF.loc[myDF.loc[:, "day_of_the_week"]=="Monday" | myDF.loc[:, "breakfast"]=="Nothing", :]
print(monday_or_breakfast)
----

You can use `&` for the logical AND just as you can use `|` for the logical OR: 

[source,python]
----
apple_and_one = myDF.loc[(myDF.loc[:, "breakfast"]=="Apple") & (myDF.loc[:, "nonsense"]==1), :]
print(apple_and_one)
----

----
  day_of_the_week breakfast  nonsense
1          Monday     Apple         1
----

{sp}+

==== Flights.csv example

.Click to see solution
[%collapsible]
====
Take the following example from the "flights_sample.csv" file:

[source,python]
----
import pandas as pd

myDF = pd.read_csv("flights_sample.csv")
print(myDF.head())
----

----
   Year  Month  DayofMonth  ...  NASDelay  SecurityDelay  LateAircraftDelay 
0  1987     10          14  ...       NaN            NaN                NaN
1  1990     10          15  ...       NaN            NaN                NaN
2  1990     10          17  ...       NaN            NaN                NaN
3  1990     10          18  ...       NaN            NaN                NaN
4  1991     10          19  ...       NaN            NaN                NaN
----

This call to `head` would be the equivalent to the line `myDF.loc[0:4, :]`. The comma is important here -- everything before the comma indicates row selection, while everything after indicates column selection. You should recognize the `:` from slicing, and we can now slice on _both_ dimensions thanks to `loc`!

Let's say we want only the data from 1990 -- we can accomplish this using a *conditional*, which is very important for selecting what we want; you'll be seeing a lot of conditionals in this page _and_ in your indexing future.

[source,python]
----
# option 1: nested .loc call
love_the_90s = myDF.loc[myDF.loc[:, 'Year'] == 1990, :]
# option 2: nested bracket selection; equivalent to 1
love_the_90s = myDF.loc[myDF['Year'] == 1990, :]
print(love_the_90s)
----

----
   Year  Month  DayofMonth  ...  NASDelay  SecurityDelay  LateAircraftDelay
1  1990     10          15  ...       NaN            NaN                NaN
2  1990     10          17  ...       NaN            NaN                NaN
3  1990     10          18  ...       NaN            NaN                NaN
----

Cool! This gives us what we want... but what's with the weird nesting? The thing with conditionals is that the statement only evaluates to `True` or `False` -- boolean values, in other words. In our example, the statement `myDF['Year'] == 1990` on its own would evaluate to:

[source,python]
----
0    False
1     True
2     True
3     True
4    False
----

Obviously this only gives us information on `Year` and its values, but now we know *which rows* contain the information we want. We now nest our row selection in its proper location within our outer `.loc` call, then use `:` to select all columns of `myDF`. _This_ is why nesting was necessary.

{sp}+

Now, how do we repeat this example with `.iloc`? We can try swapping `.loc` with `.iloc` directly in Option 1, but we'll run into the error message `ValueError: Location based indexing can only have [integer, integer slice (START point is INCLUDED, END point is EXCLUDED), listlike of integers, boolean array] types`. This is a long way of saying we can only include _numbers_ or _a boolean list_ when using `.iloc`.

Knowing the above knowledge, we see that `Year` is the first column in `myDF`, corresponding to 0 (since `pandas` uses 0-indexing). This works for the inner call, but notice how we said `iloc` works on boolean _lists_, *not* boolean `Series`. If we try to use `iloc` on the outer call, we get another error, meaning that we need to keep it as `loc`: 

[source,python]
----
# option 3: nested .iloc call
love_the_90s = myDF.loc[myDF.iloc[:, 'Year'] == 1990, :]
print(love_the_90s)
----

----
   Year  Month  DayofMonth  ...  NASDelay  SecurityDelay  LateAircraftDelay
1  1990     10          15  ...       NaN            NaN                NaN
2  1990     10          17  ...       NaN            NaN                NaN
3  1990     10          18  ...       NaN            NaN                NaN
----
====